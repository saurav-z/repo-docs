# HunyuanWorld 1.0: Create Interactive 3D Worlds from Text and Images

**Unleash your imagination and build immersive 3D worlds with HunyuanWorld 1.0, the first open-source model for generating explorable 3D environments.**  Explore the original repository on [GitHub](https://github.com/Tencent-Hunyuan/HunyuanWorld-1.0).

[//]: # (  <a href=# target="_blank"><img src=https://img.shields.io/badge/Report-b5212f.svg?logo=arxiv height=22px></a>)

[//]: # (  <a href=# target="_blank"><img src= https://img.shields.io/badge/Colab-8f2628.svg?logo=googlecolab height=22px></a>)

[//]: # (  <a href="#"><img alt="PyPI - Downloads" src="https://img.shields.io/pypi/v/mulankit?logo=pypi"  height=22px></a>)

<br>

<p align="center">
  <img src="assets/teaser.png">
</p>

## Key Features

*   **Text-to-3D & Image-to-3D Generation:** Create detailed 3D worlds from simple text prompts or existing images.
*   **360¬∞ Immersive Experiences:** Generate panoramic world proxies for realistic and engaging exploration.
*   **Mesh Export Capabilities:** Seamlessly integrate generated worlds with existing computer graphics pipelines.
*   **Disentangled Object Representations:** Enhance interactivity through separate object manipulation and customization.
*   **High-Quality Results:** Achieve state-of-the-art performance in visual quality and geometric consistency.
*   **Quantization and Caching Support:** Optimize memory usage and speed up inference with practical solutions.
*   **Open-Source and Accessible:** Access model checkpoints, inference code, and a technical report.
*   **Fast 3D Reconstruction**: Support fast 3D reconstruction and 3D-consistent world exploration
*   **Support consumer-grade GPUs**: Runs on Consumer-grade GPUs such as 4090!

## What's New

*   **[September 2, 2025]** Released RGB-D Video Diffusion model [HunyuanWorld-Voyager](https://github.com/Tencent-Hunyuan/HunyuanWorld-Voyager/), which supports 3D-consistency world exploration and fast 3D reconstruction!
*   **[August 15, 2025]** Released the quantization version of HunyuanWorld-1.0 (HunyuanWorld-1.0-lite), which now supports running on Consumer-grade GPUs such as 4090!
*   **[July 26, 2025]** Released the [technical report](https://arxiv.org/abs/2507.21809) of HunyuanWorld-1.0.
*   **[July 26, 2025]** Initial release of HunyuanWorld-1.0.

Join our **[Discord](https://discord.gg/dNBrdrGGMa)** group for discussion and support.

## ‚òØÔ∏è **HunyuanWorld 1.0 Overview**

### Abstract

HunyuanWorld 1.0 overcomes the challenges of generating immersive, playable 3D worlds from text or images. It combines the benefits of video-based methods (diversity) and 3D-based methods (geometric consistency) with a novel framework. Key advantages include 360¬∞ immersive experiences, mesh export capabilities, and disentangled object representations. It uses a semantically layered 3D mesh representation leveraging panoramic images for world decomposition and reconstruction.

<p align="center">
  <img src="assets/application.png">
</p>

### Architecture

The architecture seamlessly integrates panoramic proxy generation, semantic layering, and hierarchical 3D reconstruction to create high-quality, scene-scale 360¬∞ 3D worlds, supporting both text and image inputs.

<p align="left">
  <img src="assets/arch.jpg">
</p>

### Performance

HunyuanWorld 1.0 demonstrates superior performance compared to other open-source panorama generation and 3D world generation methods based on numerical results.

**Performance Metrics:** *The original README contains tables of metrics such as BRISQUE, NIQE, Q-Align, and CLIP scores.  Those tables would be included here if this was a full rewrite, but have been excluded to simplify the response.*

### Visual Results

Experience immersive and explorable 3D worlds generated by HunyuanWorld 1.0:

<p align="left">
  <img src="assets/panorama1.gif">
</p>

<p align="left">
  <img src="assets/panorama2.gif">
</p>

<p align="left">
  <img src="assets/roaming_world.gif">
</p>

## üéÅ Models Zoo

The open-source version of HunyuanWorld 1.0 is based on Flux and can be adapted to other image generation models such as Hunyuan Image, Kontext, and Stable Diffusion.

| Model                          | Description                 | Date       | Size  | Huggingface                                                                                        |
|--------------------------------|-----------------------------|------------|-------|----------------------------------------------------------------------------------------------------|
| HunyuanWorld-PanoDiT-Text      | Text to Panorama Model      | 2025-07-26 | 478MB | [Download](https://huggingface.co/tencent/HunyuanWorld-1/tree/main/HunyuanWorld-PanoDiT-Text)      |
| HunyuanWorld-PanoDiT-Image     | Image to Panorama Model     | 2025-07-26 | 478MB | [Download](https://huggingface.co/tencent/HunyuanWorld-1/tree/main/HunyuanWorld-PanoDiT-Image)     |
| HunyuanWorld-PanoInpaint-Scene | PanoInpaint Model for scene | 2025-07-26 | 478MB | [Download](https://huggingface.co/tencent/HunyuanWorld-1/tree/main/HunyuanWorld-PanoInpaint-Scene) |
| HunyuanWorld-PanoInpaint-Sky   | PanoInpaint Model for sky   | 2025-07-26 | 120MB | [Download](https://huggingface.co/tencent/HunyuanWorld-1/tree/main/HunyuanWorld-PanoInpaint-Sky)   |

## ü§ó Get Started

Follow these steps to use HunyuanWorld 1.0:

### Environment Setup

*   Requires Python 3.10 and PyTorch 2.5.0+cu124.
*   Clone the repository and create a Conda environment using the provided YAML file:

    ```bash
    git clone https://github.com/Tencent-Hunyuan/HunyuanWorld-1.0.git
    cd HunyuanWorld-1.0
    conda env create -f docker/HunyuanWorld.yaml
    ```

*   Install dependencies, including Real-ESRGAN, ZIM, and Draco (for exporting in Draco format). Instructions provided in the original README are included for completeness.
*   Hugging Face login.

### Code Usage

Example usage with Image to World Generation and Text to World generation. The code snippets from the original README have been included.

### Quantization & Cache Usage

The code snippets from the original README have been included.

### Quick Start

*   Run the provided test script for a quick start:

    ```bash
    bash scripts/test.sh
    ```

### 3D World Viewer

Use the ModelViewer tool (```modelviewer.html```) to visualize your generated 3D scenes in a web browser.

<p align="left">
  <img src="assets/quick_look.gif">
</p>

## üìë Open-Source Plan

*   [x] Inference Code
*   [x] Model Checkpoints
*   [x] Technical Report
*   [x] Lite Version
*   [x] Voyager (RGBD Video Diffusion)

## üîó BibTeX

```
@article{hunyuanworld2025tencent,
    title={HunyuanWorld 1.0: Generating Immersive, Explorable, and Interactive 3D Worlds from Words or Pixels},
    author={Team HunyuanWorld},
    year={2025},
    journal={arXiv preprint}
}
```

## Contact

For any questions, please contact tengfeiwang12@gmail.com.

## Acknowledgements

We are grateful to the contributors of [Stable Diffusion](https://github.com/Stability-AI/stablediffusion), [FLUX](https://github.com/black-forest-labs/flux), [diffusers](https://github.com/huggingface/diffusers), [HuggingFace](https://huggingface.co), [Real-ESRGAN](https://github.com/xinntao/Real-ESRGAN), [ZIM](https://github.com/naver-ai/ZIM), [GroundingDINO](https://github.com/IDEA-Research/GroundingDINO), [MoGe](https://github.com/microsoft/moge), [Worldsheet](https://worldsheet.github.io/), [WorldGen](https://github.com/ZiYang-xie/WorldGen).