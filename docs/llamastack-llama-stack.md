# Llama Stack: Build Powerful AI Applications with Ease

**Llama Stack provides a unified and flexible platform to streamline the development and deployment of generative AI applications. Explore the official [Llama Stack repository](https://github.com/llamastack/llama-stack) for more information.**

## Key Features of Llama Stack:

*   **Unified API Layer:**  Standardizes core building blocks for AI application development, including inference, RAG, agents, tools, safety, and more.
*   **Plugin Architecture:** Supports diverse API implementations across various environments (local, on-premise, cloud, mobile).
*   **Prepackaged Distributions:** Offers ready-to-use solutions for quick and reliable application setup.
*   **Multiple Developer Interfaces:** Provides CLI and SDKs for Python, Typescript, iOS, and Android, simplifying integration.
*   **Standalone Applications:** Includes example applications to guide the creation of production-grade AI solutions.
*   **Llama 4 Support:**  Easily integrate and run Llama 4 models with pre-configured setups.

##  Get Started Quickly:

*   **One-Line Installation:** `curl -LsSf https://github.com/meta-llama/llama-stack/raw/main/scripts/install.sh | bash`
*   **Quick Start Guide:**  Explore the [Getting Started](https://llama-stack.readthedocs.io/en/latest/getting_started/index.html) documentation.
*   **Interactive Tutorial:**  Try the [Colab Notebook](./docs/getting_started.ipynb) and the complete [Llama 3.2 course on Deeplearning.ai](https://learn.deeplearning.ai/courses/introducing-multimodal-llama-3-2/lesson/8/llama-stack).

## Benefits of Using Llama Stack:

*   **Flexible Infrastructure:** Choose your preferred infrastructure without code changes.
*   **Consistent Experience:** Unified APIs ensure consistent behavior across applications.
*   **Robust Ecosystem:** Benefit from integrations with leading providers for tailored solutions.

## Supported API Providers:

Llama Stack integrates with a wide range of API providers, allowing you to choose the best fit for your needs.  See the complete and updated list [here](https://llama-stack.readthedocs.io/en/latest/providers/index.html)

## Distributions:

Easily deploy with pre-configured distributions. Find the right one for you!

| Distribution | Docker | Start This Distribution |
| :--------------- | :--------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------ |
| Starter Distribution  | [llamastack/distribution-starter](https://hub.docker.com/repository/docker/llamastack/distribution-starter/general) | [Guide](https://llama-stack.readthedocs.io/en/latest/distributions/self_hosted_distro/starter.html) |
| Meta Reference | [llamastack/distribution-meta-reference-gpu](https://hub.docker.com/repository/docker/llamastack/distribution-meta-reference-gpu/general) | [Guide](https://llama-stack.readthedocs.io/en/latest/distributions/self_hosted_distro/meta-reference-gpu.html) |
| PostgreSQL | [llamastack/distribution-postgres-demo](https://hub.docker.com/repository/docker/llamastack/distribution-postgres-demo/general) | |

##  Client SDKs

Integrate Llama Stack into your projects with SDKs for various languages.

| Language | Client SDK | Package |
| :----: | :----: | :----: |
| Python | [llama-stack-client-python](https://github.com/meta-llama/llama-stack-client-python) | [![PyPI version](https://img.shields.io/pypi/v/llama_stack_client.svg)](https://pypi.org/project/llama_stack_client/) |
| Swift  | [llama-stack-client-swift](https://github.com/meta-llama/llama-stack-client-swift) | [![Swift Package Index](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fmeta-llama%2Fllama-stack-client-swift%2Fbadge%3Ftype%3Dswift-versions)](https://swiftpackageindex.com/meta-llama/llama-stack-client-swift) |
| Typescript   | [llama-stack-client-typescript](https://github.com/meta-llama/llama-stack-client-typescript) | [![NPM version](https://img.shields.io/npm/v/llama-stack-client.svg)](https://npmjs.org/package/llama-stack-client) |
| Kotlin | [llama-stack-client-kotlin](https://github.com/meta-llama/llama-stack-client-kotlin) | [![Maven version](https://img.shields.io/maven-central/v/com.llama.llamastack/llama-stack-client-kotlin)](https://central.sonatype.com/artifact/com.llama.llamastack/llama-stack-client-kotlin) |

## Documentation and Resources:

*   **CLI References:** [llama (server-side) CLI Reference](https://llama-stack.readthedocs.io/en/latest/references/llama_cli_reference/index.html) and [llama (client-side) CLI Reference](https://llama-stack.readthedocs.io/en/latest/references/llama_stack_client_cli_reference.html)
*   **Complete Documentation:** Access the comprehensive [documentation](https://llama-stack.readthedocs.io/en/latest/index.html).
*   **Contribute:** Learn how to contribute [here](CONTRIBUTING.md) and add a new API provider [here](https://llama-stack.readthedocs.io/en/latest/contributing/new_api_provider.html).
*   **Llama Stack Apps:** For more example scripts with client SDKs, check out the [llama-stack-apps](https://github.com/meta-llama/llama-stack-apps/tree/main/examples) repository.

## Community:

*   Join the [Discord](https://discord.gg/llama-stack) community.

## Star History:

[![Star History Chart](https://api.star-history.com/svg?repos=meta-llama/llama-stack&type=Date)](https://www.star-history.com/#meta-llama/llama-stack&Date)

## Contributors:

Thanks to all our amazing contributors!

<a href="https://github.com/meta-llama/llama-stack/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=meta-llama/llama-stack" />
</a>