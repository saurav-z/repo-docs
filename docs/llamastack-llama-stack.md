# Llama Stack: Build Generative AI Applications Faster

Llama Stack simplifies the development of AI applications by providing a unified API layer and pre-packaged distributions, making it easier to build, deploy, and scale your models. Check out the [original repo](https://github.com/llamastack/llama-stack) for more details.

**Key Features:**

*   **Unified API Layer:** Access inference, RAG, agents, tools, safety, evals, and telemetry with a single API.
*   **Plugin Architecture:** Supports a wide range of API implementations across various environments (local, cloud, on-premise).
*   **Pre-packaged Distributions:** Get started quickly with verified distributions for different deployment scenarios.
*   **Multiple Developer Interfaces:** Access Llama Stack through CLI, and SDKs in Python, Typescript, Swift, and Kotlin.
*   **Production-Ready Examples:** Build real-world AI applications with standalone examples.

**Benefits:**

*   **Flexibility:** Choose your preferred infrastructure without changing your application code.
*   **Consistency:** Build, test, and deploy AI applications with consistent behavior through unified APIs.
*   **Extensive Ecosystem:** Leverage integrations with leading cloud providers, hardware vendors, and AI-focused companies.

## ðŸš€ Getting Started

**One-Line Installation:**

```bash
curl -LsSf https://github.com/meta-llama/llama-stack/raw/main/scripts/install.sh | bash
```

## Overview

Llama Stack streamlines AI application development by providing essential building blocks. It codifies best practices across the Llama ecosystem, offering a comprehensive solution for developers.

[Image of Llama Stack Architecture (as provided in original README)]

## ðŸ¤– API Providers

Llama Stack supports a wide range of API providers, including:

**(Table of providers, as provided in original README)**

[Find the full list](https://llama-stack.readthedocs.io/en/latest/providers/index.html).

## ðŸ“¦ Distributions

Llama Stack Distributions offer pre-configured bundles for easy deployment.

**(Table of Distributions, as provided in original README)**

## ðŸ“š Documentation

Comprehensive documentation is available to guide you:

*   [Quick Start](https://llama-stack.readthedocs.io/en/latest/getting_started/index.html)
*   [CLI References](https://llama-stack.readthedocs.io/en/latest/references/llama_cli_reference/index.html)
*   [SDK Guides](https://llama-stack.readthedocs.io/en/latest/index.html)
*   [Contributing](CONTRIBUTING.md)

## ðŸ’» Client SDKs

Build your applications in your preferred language:

**(Table of client SDKs, as provided in original README)**

## âœ¨ Contributors

**(Contributors section, as provided in original README)**

## ðŸŒŸ GitHub Star History

**(Star History Chart, as provided in original README)**