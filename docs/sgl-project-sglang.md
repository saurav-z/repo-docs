<div align="center" id="sglangtop">
<img src="https://raw.githubusercontent.com/sgl-project/sglang/main/assets/logo.png" alt="logo" width="400" margin="10px"></img>

[![PyPI](https://img.shields.io/pypi/v/sglang)](https://pypi.org/project/sglang)
![PyPI - Downloads](https://img.shields.io/pypi/dm/sglang)
[![license](https://img.shields.io/github/license/sgl-project/sglang.svg)](https://github.com/sgl-project/sglang/tree/main/LICENSE)
[![issue resolution](https://img.shields.io/github/issues-closed-raw/sgl-project/sglang)](https://github.com/sgl-project/sglang/issues)
[![open issues](https://img.shields.io/github/issues-raw/sgl-project/sglang)](https://github.com/sgl-project/sglang/issues)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/sgl-project/sglang)

</div>

# SGLang: High-Performance Serving Framework for LLMs and Vision Language Models

SGLang empowers lightning-fast and controllable interactions with large language models and vision language models, unlocking unprecedented efficiency and performance.  [Explore the original repository](https://github.com/sgl-project/sglang).

## Key Features of SGLang

*   **Blazing-Fast Backend Runtime**: Experience unparalleled efficiency with features like RadixAttention, zero-overhead CPU scheduling, prefill-decode disaggregation, speculative decoding, continuous batching, paged attention, tensor/pipeline/expert parallelism, structured outputs, chunked prefill, and quantization (FP8/INT4/AWQ/GPTQ), and multi-lora batching.
*   **Intuitive Frontend Language**: Simplify LLM application development with a flexible interface that includes chained generation calls, advanced prompting, control flow, multi-modal inputs, parallelism, and external interactions.
*   **Extensive Model Support**: Seamlessly integrate with a wide range of generative models (Llama, Gemma, Mistral, Qwen, DeepSeek, LLaVA, etc.), embedding models (e5-mistral, gte, mcdse) and reward models (Skywork), ensuring broad compatibility and ease of expansion.
*   **Active Community and Industry Adoption**: Benefit from a thriving open-source community and its proven track record, with SGLang deployed at leading enterprises and institutions, processing trillions of tokens daily and running on over 1,000,000 GPUs worldwide.

## Getting Started

*   [Install SGLang](https://docs.sglang.ai/start/install.html)
*   [Quick Start](https://docs.sglang.ai/backend/send_request.html)
*   [Backend Tutorial](https://docs.sglang.ai/backend/openai_api_completions.html)
*   [Frontend Tutorial](https://docs.sglang.ai/frontend/frontend.html)
*   [Contribution Guide](https://docs.sglang.ai/references/contribution_guide.html)

## Performance Benchmarks

For detailed performance insights, refer to the release blogs: [v0.2 blog](https://lmsys.org/blog/2024-07-25-sglang-llama3/), [v0.3 blog](https://lmsys.org/blog/2024-09-04-sglang-v0-3/), [v0.4 blog](https://lmsys.org/blog/2024-12-04-sglang-v0-4/).

## Roadmap

[Development Roadmap (2025 H1)](https://github.com/sgl-project/sglang/issues/4042)

## Adoption and Sponsorship

<p align="center">
  <img src="https://raw.githubusercontent.com/sgl-project/sgl-learning-materials/refs/heads/main/slides/adoption.png" alt="logo" width="800" margin="10px">
</p>

SGLang is a trusted solution adopted by leading organizations including xAI, AMD, NVIDIA, Intel, LinkedIn, Cursor, Oracle Cloud, Google Cloud, Microsoft Azure, AWS, Atlas Cloud, Voltage Park, Nebius, DataCrunch, Novita, InnoMatrix, MIT, UCLA, the University of Washington, Stanford, UC Berkeley, Tsinghua University, Jam & Tea Studios, Baseten, and other major technology organizations.

## Contact Us

For partnerships, technical consulting, or sponsorship opportunities, please contact us at contact@sglang.ai.

## Acknowledgment

We learned the design and reused code from the following projects: [Guidance](https://github.com/guidance-ai/guidance), [vLLM](https://github.com/vllm-project/vllm), [LightLLM](https://github.com/ModelTC/lightllm), [FlashInfer](https://github.com/flashinfer-ai/flashinfer), [Outlines](https://github.com/outlines-dev/outlines), and [LMQL](https://github.com/eth-sri/lmql).
```

Key improvements and SEO optimizations:

*   **Concise and Engaging Hook:**  A one-sentence summary that highlights the core value proposition.
*   **Clear Headings:**  Organized content for readability and SEO benefits.
*   **Keyword Optimization:**  Uses relevant keywords like "large language models," "vision language models," "high-performance," "serving framework," and model names like "Llama," "Mistral," and "DeepSeek."
*   **Bulleted Key Features:**  Easy-to-scan list of benefits.
*   **Clear "Getting Started" Section:**  Provides easy access to installation and tutorials.
*   **Emphasis on Performance:**  Highlights performance benchmarks and provides links to relevant blog posts.
*   **Adoption & Sponsorship Section:** Showcases trust and opportunities.
*   **Contact Information:** Makes it easy to get in touch.
*   **Alt Text for Images**: Added alt text to the logo image.
*   **Links**: The links are kept for navigation purposes.
*   **Simplified News Section:** Removed the news section to reduce verbosity and complexity.
*   **Removed "More" Section:** Simplified the content for a cleaner presentation.