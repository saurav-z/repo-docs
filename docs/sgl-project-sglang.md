<div align="center">
<img src="https://raw.githubusercontent.com/sgl-project/sglang/main/assets/logo.png" alt="SGLang Logo" width="400" margin="10px">
</div>

[![PyPI](https://img.shields.io/pypi/v/sglang)](https://pypi.org/project/sglang)
![PyPI - Downloads](https://img.shields.io/pypi/dm/sglang)
[![license](https://img.shields.io/github/license/sgl-project/sglang.svg)](https://github.com/sgl-project/sglang/tree/main/LICENSE)
[![issue resolution](https://img.shields.io/github/issues-closed-raw/sgl-project/sglang)](https://github.com/sgl-project/sglang/issues)
[![open issues](https://img.shields.io/github/issues-raw/sgl-project/sglang)](https://github.com/sgl-project/sglang/issues)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/sgl-project/sglang)

## SGLang: High-Performance LLM Serving for Production

SGLang is a powerful, open-source serving framework designed to accelerate and streamline large language model (LLM) deployments, offering exceptional performance and control. **[Explore the SGLang GitHub Repository](https://github.com/sgl-project/sglang) for more details.**

**Key Features:**

*   üöÄ **Fast Backend Runtime:** Experience blazing-fast serving with features like RadixAttention, zero-overhead CPU scheduling, and expert parallelism for efficient LLM inference.
*   ‚úçÔ∏è **Flexible Frontend Language:** Simplify LLM application development with an intuitive interface supporting chained generation, advanced prompting, control flow, multi-modal inputs, and external interactions.
*   üåê **Extensive Model Support:** Easily deploy a wide variety of generative models (Llama, Gemma, Mistral, Qwen, DeepSeek, LLaVA, etc.), embedding models, and reward models, with extensibility for new models.
*   ü§ù **Active Community & Industry Adoption:** Benefit from a vibrant open-source community and a production-proven framework trusted by leading enterprises and institutions.

## Core Capabilities & Benefits

*   **Optimized Performance:** Achieve significant speedups through techniques like speculative decoding, continuous batching, and quantization (FP8/INT4/AWQ/GPTQ).
*   **Simplified Development:** Write cleaner, more efficient LLM applications with SGLang's intuitive frontend language.
*   **Scalability & Reliability:** Serve LLMs at scale with features like tensor parallelism, pipeline parallelism, and expert parallelism, ensuring robust deployments.
*   **Comprehensive Model Support:** Leverage out-of-the-box support for popular LLMs and easily integrate new models.

## Getting Started

*   [**Install SGLang**](https://docs.sglang.ai/start/install.html)
*   [**Quick Start Guide**](https://docs.sglang.ai/backend/send_request.html)
*   [**Backend Tutorial**](https://docs.sglang.ai/backend/openai_api_completions.html)
*   [**Frontend Tutorial**](https://docs.sglang.ai/frontend/frontend.html)
*   [**Contribution Guide**](https://docs.sglang.ai/references/contribution_guide.html)

## Performance & Benchmarks

SGLang consistently delivers superior performance.  Refer to the following resources for in-depth benchmarks and performance comparisons:

*   [v0.2 Blog](https://lmsys.org/blog/2024-07-25-sglang-llama3/)
*   [v0.3 Blog](https://lmsys.org/blog/2024-09-04-sglang-v0-3/)
*   [v0.4 Blog](https://lmsys.org/blog/2024-12-04-sglang-v0-4/)
*   [Large-scale expert parallelism](https://lmsys.org/blog/2025-05-05-large-scale-ep/)

## Roadmap

*   [Development Roadmap (2025 H2)](https://github.com/sgl-project/sglang/issues/7736)

## Adoption and Sponsorship

SGLang is a trusted solution deployed at scale, serving trillions of tokens daily for leading organizations across various industries.

<img src="https://raw.githubusercontent.com/sgl-project/sgl-learning-materials/refs/heads/main/slides/adoption.png" alt="logo" width="800" margin="10px">

## Contact

For inquiries regarding large-scale deployment, technical consulting, sponsorships, or partnerships, please contact us at [contact@sglang.ai](mailto:contact@sglang.ai).

## Acknowledgements

SGLang is inspired by and builds upon the work of the following projects:
*   [Guidance](https://github.com/guidance-ai/guidance)
*   [vLLM](https://github.com/vllm-project/vllm)
*   [LightLLM](https://github.com/ModelTC/lightllm)
*   [FlashInfer](https://github.com/flashinfer-ai/flashinfer)
*   [Outlines](https://github.com/outlines-dev/outlines)
*   [LMQL](https://github.com/eth-sri/lmql)
```
Key improvements and SEO considerations:

*   **Clear and Concise Title:** Uses the project name and a strong descriptor ("High-Performance LLM Serving").
*   **One-Sentence Hook:** Captures the essence of SGLang's value proposition.
*   **Keyword Optimization:** Includes relevant keywords throughout the text, such as "LLM serving," "large language models," "inference," "performance," "framework," and model names.
*   **Structured Headings:** Uses clear headings and subheadings to organize information and improve readability.
*   **Bulleted Key Features:** Highlights the main benefits in an easily digestible format.
*   **Call to Action:** Encourages exploration of the project's GitHub repository and key resources.
*   **Concise Explanations:** Provides brief but informative descriptions of the core features and benefits.
*   **Links to Key Resources:** Includes direct links to installation, tutorials, and documentation.
*   **Adoption and Sponsorship Section:**  Highlights the widespread adoption of SGLang and provides contact information for interested parties.
*   **SEO-Friendly Formatting:** Uses Markdown formatting to make the content easily readable by search engines.
*   **Improved Readability:**  Rephrased sentences and restructured content for better flow and understanding.
*   **Removed redundant information:** Removed details that didn't contribute directly to the project's value.
*   **Contact information and Acknowledgements are preserved.**