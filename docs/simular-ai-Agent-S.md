<div align="center">
  <img src="images/agent_s.png" alt="Agent S Logo" style="vertical-align:middle" width="60">
  <h1>Agent S: Empowering Computers with Human-Like Intelligence</h1>
</div>

<p align="center">Agent S enables your computer to perform tasks autonomously, offering a groundbreaking approach to AI-driven computer interaction.  Explore the project on <a href="https://github.com/simular-ai/Agent-S">GitHub</a>!
  <br>
  <br>
  üåê <a href="https://www.simular.ai/articles/agent-s2-technical-review">[S2 blog]</a>&nbsp;
  üìÑ <a href="https://arxiv.org/abs/2504.00906">[S2 Paper (COLM 2025)]</a>&nbsp;
  üé• <a href="https://www.youtube.com/watch?v=wUGVQl7c0eg">[S2 Video]</a>
  <br>
  üåê <a href="https://www.simular.ai/agent-s">[S1 blog]</a>&nbsp;
  üìÑ <a href="https://arxiv.org/abs/2410.08164">[S1 Paper (ICLR 2025)]</a>&nbsp;
  üé• <a href="https://www.youtube.com/watch?v=OBDE3Knte0g">[S1 Video]</a>
</p>

<div align="center">
  <a href="https://trendshift.io/repositories/13151" target="_blank">
    <img src="https://trendshift.io/api/badge/repositories/13151" alt="simular-ai%2FAgent-S | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"/>
  </a>
</div>

<div align="center">
  <img src="https://img.shields.io/badge/OS-Windows-blue?logo=windows&logoColor=white" alt="Windows">
  <img src="https://img.shields.io/badge/OS-macOS-black?logo=apple&logoColor=white" alt="macOS">
  <img src="https://img.shields.io/badge/OS-Linux-yellow?logo=linux&logoColor=black" alt="Linux">
  <a href="https://discord.gg/E2XfsK9fPV">
    <img src="https://dcbadge.limes.pink/api/server/https://discord.gg/E2XfsK9fPV?style=flat" alt="Discord">
  </a>
  &nbsp;&nbsp;
  <a href="https://pepy.tech/projects/gui-agents">
    <img src="https://static.pepy.tech/badge/gui-agents" alt="PyPI Downloads">
  </a>
</div>

<div align="center">
  <!-- Keep these links. Translations will automatically update with the README. -->
  <a href="https://www.readme-i18n.com/simular-ai/Agent-S?lang=de">Deutsch</a> |
  <a href="https://www.readme-i18n.com/simular-ai/Agent-S?lang=es">Espa√±ol</a> |
  <a href="https://www.readme-i18n.com/simular-ai/Agent-S?lang=fr">fran√ßais</a> |
  <a href="https://www.readme-i18n.com/simular-ai/Agent-S?lang=ja">Êó•Êú¨Ë™û</a> |
  <a href="https://www.readme-i18n.com/simular-ai/Agent-S?lang=ko">ÌïúÍµ≠Ïñ¥</a> |
  <a href="https://www.readme-i18n.com/simular-ai/Agent-S?lang=pt">Portugu√™s</a> |
  <a href="https://www.readme-i18n.com/simular-ai/Agent-S?lang=ru">–†—É—Å—Å–∫–∏–π</a> |
  <a href="https://www.readme-i18n.com/simular-ai/Agent-S?lang=zh">‰∏≠Êñá</a>
</div>

<div align="center">
  &nbsp;&nbsp;
  <p>Skip the setup? Try Agent S in <a href="https://cloud.simular.ai/">Simular Cloud</a>
</div>

## Key Features

*   **Autonomous Task Execution:** Agent S enables your computer to perform complex tasks autonomously, mimicking human interaction.
*   **Open-Source Framework:** Build your own intelligent GUI agents.
*   **Cutting-Edge Performance:** Agent S2.5 achieves state-of-the-art results on OSWorld and other benchmarks.
*   **Cross-Platform Compatibility:** Supports Windows, macOS, and Linux.
*   **Easy Installation & Usage:** Get started quickly with straightforward installation and API configurations.

## üöÄ Updates

*   **2025/08/01:** Agent S2.5 is released (gui-agents v0.2.5): simpler, better, and faster! New SOTA on [OSWorld-Verified](https://os-world.github.io)!
*   **2025/07/07:** The [Agent S2 paper](https://arxiv.org/abs/2504.00906) is accepted to COLM 2025! See you in Montreal!
*   **2025/04/27:** The Agent S paper won the Best Paper Award üèÜ at ICLR 2025 Agentic AI for Science Workshop!
*   **2025/04/01:** Released the [Agent S2 paper](https://arxiv.org/abs/2504.00906) with new SOTA results on OSWorld, WindowsAgentArena, and AndroidWorld!
*   **2025/03/12:** Released Agent S2 along with v0.2.0 of [gui-agents](https://github.com/simular-ai/Agent-S), the new state-of-the-art for computer use agents (CUA), outperforming OpenAI's CUA/Operator and Anthropic's Claude 3.7 Sonnet Computer-Use!
*   **2025/01/22:** The [Agent S paper](https://arxiv.org/abs/2410.08164) is accepted to ICLR 2025!
*   **2025/01/21:** Released v0.1.2 of [gui-agents](https://github.com/simular-ai/Agent-S) library, with support for Linux and Windows!
*   **2024/12/05:** Released v0.1.0 of [gui-agents](https://github.com/simular-ai/Agent-S) library, allowing you to use Agent-S for Mac, OSWorld, and WindowsAgentArena with ease!
*   **2024/10/10:** Released the [Agent S paper](https://arxiv.org/abs/2410.08164) and codebase!

## Table of Contents

1.  [üí° Introduction](#-introduction)
2.  [üéØ Current Results](#-current-results)
3.  [üõ†Ô∏è Installation & Setup](#%EF%B8%8F-installation--setup)
4.  [üöÄ Usage](#-usage)
5.  [ü§ù Acknowledgements](#-acknowledgements)
6.  [üí¨ Citation](#-citation)

## üí° Introduction

Agent S is an open-source framework designed to enable autonomous interaction with computers through Agent-Computer Interface, offering a revolutionary way to interact with your computer. Join us in building intelligent GUI agents capable of learning and performing complex tasks automatically!

## üéØ Current Results

<div align="center">
  <table border="0" cellspacing="0" cellpadding="5">
    <tr>
      <th>Benchmark</th>
      <th>Agent S2.5</th>
      <th>Previous SOTA</th>
    </tr>
    <tr>
      <td>OSWorld Verified (100 step)</td>
      <td><b>56.0%</b></td>
      <td>53.1%</td>
    </tr>
    <tr>
      <td>OSWorld Verified (50 step)</td>
      <td><b>54.2%</b></td>
      <td>50.6%</td>
    </tr>
  </table>
</div>

## üõ†Ô∏è Installation & Setup

### Prerequisites

*   **Single Monitor**: Agent S is optimized for single monitor setups.
*   **Security**:  Agent S runs Python code to control your computer; please use with caution.
*   **Supported Platforms**: Linux, Mac, and Windows.

### Installation

```bash
pip install gui-agents
```

### API Configuration

#### Option 1: Environment Variables

Add the following to your `.bashrc` (Linux) or `.zshrc` (MacOS) file:

```bash
export OPENAI_API_KEY=<YOUR_API_KEY>
export ANTHROPIC_API_KEY=<YOUR_ANTHROPIC_API_KEY>
export HF_TOKEN=<YOUR_HF_TOKEN>
```

#### Option 2: Python Script

```python
import os
os.environ["OPENAI_API_KEY"] = "<YOUR_API_KEY>"
```

### Supported Models

Agent S supports Azure OpenAI, Anthropic, Gemini, Open Router, and vLLM inference. See [models.md](models.md) for further details.

### Grounding Models (Required)

For optimal performance, we recommend [UI-TARS-1.5-7B](https://huggingface.co/ByteDance-Seed/UI-TARS-1.5-7B) or another provider.  See [Hugging Face Inference Endpoints](https://huggingface.co/learn/cookbook/en/enterprise_dedicated_endpoints) for setup instructions.

## üöÄ Usage

>   ‚ö°Ô∏è **Recommended Setup:**  
>   For the best configuration, we recommend using **OpenAI o3-2025-04-16** as the main model, paired with **UI-TARS-1.5-7B** for grounding.

### CLI

Run Agent S2.5 with the required parameters:

```bash
agent_s \
    --provider openai \
    --model o3-2025-04-16 \
    --ground_provider huggingface \
    --ground_url http://localhost:8080 \
    --ground_model ui-tars-1.5-7b \
    --grounding_width 1920 \
    --grounding_height 1080
```

#### Required Parameters

*   **`--provider`**: Main generation model provider (e.g., openai, anthropic, etc.) - Default: "openai"
*   **`--model`**: Main generation model name (e.g., o3-2025-04-16) - Default: "o3-2025-04-16"
*   **`--ground_provider`**: The provider for the grounding model - **Required**
*   **`--ground_url`**: The URL of the grounding model - **Required**
*   **`--ground_model`**: The model name for the grounding model - **Required**
*   **`--grounding_width`**: Width of the output coordinate resolution from the grounding model - **Required**
*   **`--grounding_height`**: Height of the output coordinate resolution from the grounding model - **Required**

#### Grounding Model Dimensions

The grounding width and height should match the output coordinate resolution of your grounding model:

*   **UI-TARS-1.5-7B**: Use `--grounding_width 1920 --grounding_height 1080`
*   **UI-TARS-72B**: Use `--grounding_width 1000 --grounding_height 1000`

#### Optional Parameters

*   **`--model_url`**: Custom API URL for main generation model - Default: ""
*   **`--model_api_key`**: API key for main generation model - Default: ""
*   **`--ground_api_key`**: API key for grounding model endpoint - Default: ""
*   **`--max_trajectory_length`**: Maximum number of image turns to keep in trajectory - Default: 8
*   **`--enable_reflection`**: Enable reflection agent to assist the worker agent - Default: True

### `gui_agents` SDK

First, import the necessary modules. `AgentS2_5` is the main agent class, and `OSWorldACI` is our grounding agent.

```python
import pyautogui
import io
from gui_agents.s2_5.agents.agent_s import AgentS2_5
from gui_agents.s2_5.agents.grounding import OSWorldACI

# Load in your API keys.
from dotenv import load_dotenv
load_dotenv()

current_platform = "linux"  # "darwin", "windows"
```

Next, define engine parameters for generation and grounding.

```python
engine_params = {
  "engine_type": provider,
  "model": model,
  "base_url": model_url,     # Optional
  "api_key": model_api_key,  # Optional
}

# Load the grounding engine from a custom endpoint
ground_provider = "<your_ground_provider>"
ground_url = "<your_ground_url>"
ground_model = "<your_ground_model>"
ground_api_key = "<your_ground_api_key>"

# Set grounding dimensions based on your model's output coordinate resolution
# UI-TARS-1.5-7B: grounding_width=1920, grounding_height=1080
# UI-TARS-72B: grounding_width=1000, grounding_height=1000
grounding_width = 1920  # Width of output coordinate resolution
grounding_height = 1080  # Height of output coordinate resolution

engine_params_for_grounding = {
  "engine_type": ground_provider,
  "model": ground_model,
  "base_url": ground_url,
  "api_key": ground_api_key,  # Optional
  "grounding_width": grounding_width,
  "grounding_height": grounding_height,
}
```

Then, define the grounding agent and Agent S2.5.

```python
grounding_agent = OSWorldACI(
    platform=current_platform,
    engine_params_for_generation=engine_params,
    engine_params_for_grounding=engine_params_for_grounding,
    width=1920,  # Optional: screen width
    height=1080  # Optional: screen height
)

agent = AgentS2_5(
    engine_params,
    grounding_agent,
    platform=current_platform,
    max_trajectory_length=8,  # Optional: maximum image turns to keep
    enable_reflection=True     # Optional: enable reflection agent
)
```

Finally, query the agent:

```python
# Get screenshot.
screenshot = pyautogui.screenshot()
buffered = io.BytesIO()
screenshot.save(buffered, format="PNG")
screenshot_bytes = buffered.getvalue()

obs = {
  "screenshot": screenshot_bytes,
}

instruction = "Close VS Code"
info, action = agent.predict(instruction=instruction, observation=obs)

exec(action[0])
```

Refer to `gui_agents/s2_5/cli_app.py` for more details on the inference loop.

### OSWorld

To deploy Agent S2.5 in OSWorld, follow the [OSWorld Deployment instructions](osworld_setup/s2_5/OSWorld.md).

## üí¨ Citations

If you find this codebase useful, please cite:

```
@misc{Agent-S2,
      title={Agent S2: A Compositional Generalist-Specialist Framework for Computer Use Agents},
      author={Saaket Agashe and Kyle Wong and Vincent Tu and Jiachen Yang and Ang Li and Xin Eric Wang},
      year={2025},
      eprint={2504.00906},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2504.00906},
}

@inproceedings{Agent-S,
    title={{Agent S: An Open Agentic Framework that Uses Computers Like a Human}},
    author={Saaket Agashe and Jiuzhou Han and Shuyu Gan and Jiachen Yang and Ang Li and Xin Eric Wang},
    booktitle={International Conference on Learning Representations (ICLR)},
    year={2025},
    url={https://arxiv.org/abs/2410.08164}
}
```

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=simular-ai/Agent-S&type=Date)](https://star-history.com/#simular-ai/Agent-S&Date)