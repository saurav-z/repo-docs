# verl: Unleash the Power of RL for LLMs

verl is a cutting-edge, open-source reinforcement learning (RL) library for training and aligning Large Language Models (LLMs), developed by the ByteDance Seed team and maintained by the community. [Explore the verl GitHub Repository](https://github.com/volcengine/verl).

**Key Features:**

*   ✅ **Flexible RL Algorithms:** Easily implement diverse RL algorithms like PPO, GRPO, and more.
*   ✅ **Seamless LLM Integration:** Works with existing LLM frameworks such as FSDP, Megatron-LM, vLLM, and SGLang.
*   ✅ **Efficient Resource Utilization:** Supports flexible device mapping for optimized performance across various GPU setups.
*   ✅ **Hugging Face Compatibility:** Ready to use with popular Hugging Face models.
*   ✅ **State-of-the-Art Performance:** Achieves leading-edge LLM training throughput.
*   ✅ **Multi-Modal RL**: Includes vision-language models (VLMs) and multi-modal RL support

**What's New:**

*   **[July 2025]** verl meetup at ICML Vancouver on July 16th!
*   **[July 2025]** verl keynote at AWS AI Hours Singapore on 7/8.
*   **[June 2025]** verl with Megatron backend enables large MoE models.
*   **[April 2025]** [VAPO](https://arxiv.org/pdf/2504.05118) outperforms DAPO-32B.
*   **[March 2025]** verl v0.3.0.post1 released with ~1.4x speedup.
*   **[March 2025]** verl will be presented at EuroSys 2025.

**News & Events:** Stay updated on the latest verl developments and community events. Check the original README for details.

**Getting Started:**

*   [Documentation](https://verl.readthedocs.io/en/latest/index.html)
*   [Installation](https://verl.readthedocs.io/en/latest/start/install.html)
*   [Quickstart](https://verl.readthedocs.io/en/latest/start/quickstart.html)
*   [PPO in verl](https://verl.readthedocs.io/en/latest/algo/ppo.html)
*   [GRPO in verl](https://verl.readthedocs.io/en/latest/algo/grpo.html)

**Community & Support:**

*   [Slack](https://join.slack.com/t/verlgroup/shared_invite/zt-2w5p9o4c3-yy0x2Q56s_VlGLsJ93A6vA)
*   [Twitter](https://twitter.com/verl_project)

**Citation:** If you use verl in your research, please cite the relevant papers:

*   [HybridFlow: A Flexible and Efficient RLHF Framework](https://arxiv.org/abs/2409.19256v2)
*   [A Framework for Training Large Language Models for Code Generation via Proximal Policy Optimization](https://i.cs.hku.hk/~cwu/papers/gmsheng-NL2Code24.pdf)

**Contribution:** See the [contributions guide](CONTRIBUTING.md) to get involved.

---