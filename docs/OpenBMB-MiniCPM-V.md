<div align="center">

<img src="./assets/minicpm_v_and_minicpm_o_title.png" width="500em" ></img> 

</div>

# MiniCPM-V: Unleash Powerful Multimodal AI on Your Device

**MiniCPM-V** is a series of highly efficient multimodal LLMs (MLLMs) that bring GPT-4o-level capabilities to your phone, accepting images, videos, and text for high-quality text outputs.  [Explore the original repository](https://github.com/OpenBMB/MiniCPM-V-4_5) for deeper insights and resources.

---

## Key Features:

*   **Vision-Language Powerhouse:** MiniCPM-V excels in understanding images and text, offering impressive performance across various benchmarks.
*   **On-Device Deployment:**  Designed for efficient end-side deployment, enabling powerful AI experiences on your phone.
*   **Multi-Modality Support:** Process images, videos, and text for versatile AI applications.
*   **Multilingual Capabilities:** Supports multiple languages for broader accessibility.
*   **Efficient Inference:** Optimized for fast processing, even on mobile devices.

---

## Models:

### MiniCPM-V 4.5

The latest in the MiniCPM-V series, delivering state-of-the-art vision-language capabilities.  This model builds on Qwen3-8B and SigLIP2-400M.

*   **Outperforms Competitors:** Achieves superior vision-language performance compared to GPT-4o-latest, Gemini-2.0 Pro, and Qwen2.5-VL 72B.
*   **High-FPS and Long Video Understanding:**  Innovative 3D-Resampler for efficient video processing and improved understanding of video content.
*   **Controllable Thinking Modes:** Supports both "fast" and "deep" thinking modes for optimized performance across different use cases.
*   **Enhanced Capabilities:** Features improved OCR, document parsing, and multilingual support.
*   **Ease of Use:** Supports various deployment methods, including llama.cpp, Ollama, vLLM, quantization, and more.

### MiniCPM-o 2.6

A GPT-4o level MLLM for Vision, Speech and Multimodal Live Streaming on your phone.

*   **Superior Performance:** Excels in vision, speech, and multimodal live streaming, comparable to GPT-4o-202405
*   **Real-Time Speech Conversation:** Bilingual speech conversation with configurable voices.
*   **Multimodal Streaming:** Supports live video and audio streams with real-time speech interaction.
*   **Key Advantages:** Enhanced OCR, multilingual support, and a focus on efficient end-side deployment.
*   **Token Density:** State-of-the-art token density leads to improved inference speed, memory usage, and power consumption.
*   **Easy Usage:** [llama.cpp](https://github.com/OpenBMB/llama.cpp/blob/minicpm-omni/examples/llava/README-minicpmo2.6.md), int4, GGUF, [vLLM](#efficient-inference-with-llamacpp-ollama-vllm) and [fine-tuning](./docs/llamafactory_train_and_infer.md)

---

## Explore Further:

*   [MiniCPM-V & o Cookbook](https://github.com/OpenSQZ/MiniCPM-V-CookBook): Comprehensive guides and deployment solutions.
*   [Online Demo](https://minicpm-omni-webdemo-us.modelbest.cn/): Experience the capabilities of MiniCPM-o 2.6 and other models.
*   [Local WebUI Demo](#local-webui-demo): Build your own local WebUI demo.

---