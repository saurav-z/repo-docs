<div align="center">

<img src="./assets/minicpm_v_and_minicpm_o_title.png" width="500em" alt="MiniCPM-V and MiniCPM-o Logo"></img> 

</div>

# MiniCPM-V & MiniCPM-o: Powerful On-Device Multimodal LLMs

**Experience GPT-4o-level performance on your phone with MiniCPM-V & MiniCPM-o!**  [Explore the Original Repo](https://github.com/OpenBMB/MiniCPM-V)

**Key Features:**

*   **MiniCPM-V 4.5:** The latest and most advanced version, delivering exceptional vision-language capabilities surpassing GPT-4o-latest, Gemini-2.0 Pro, and Qwen2.5-VL 72B. Features include:
    *   **High-FPS and Long Video Understanding:** Process videos with impressive speed and length, achieving up to a 96x compression rate for video tokens.
    *   **Controllable Hybrid Thinking:** Switch between fast and deep thinking modes for optimized performance in diverse scenarios.
    *   **Robust OCR and Document Parsing:** Achieve leading performance in Optical Character Recognition, handwriting and document processing.
    *   **Trustworthy Behavior and Multilingual Support:** Benefit from reliable outputs and support for over 30 languages.
    *   **Easy Deployment:** Deploy on-device and use it efficiently, and try it out with our Cookbook!

*   **MiniCPM-o 2.6:** A cutting-edge multimodal model that rivals GPT-4o in vision, speech, and multimodal live streaming:
    *   **Top-Tier Vision, Speech, and Multimodal Streaming Performance:** Matches GPT-4o in understanding images, speech, and live video/audio streams.
    *   **Real-Time Bilingual Speech Conversation:** Engage in real-time conversations in both English and Chinese with customizable voices and fun voice effects.
    *   **On-Device Multimodal Live Streaming:** Supports real-time video and audio processing on devices like iPads.
    *   **Enhanced Efficiency:** Boasts superior token density, improving inference speed and reducing memory usage.

**Key Highlights:**

*   **[MiniCPM-V & o Cookbook](https://github.com/OpenSQZ/MiniCPM-V-CookBook):** Discover detailed guides and deployment solutions for rapid implementation.
*   **[Hugging Face Demos](https://huggingface.co/spaces/openbmb/MiniCPM-Llama3-V-2_5) and [Web Demos](https://minicpm-omni-webdemo-us.modelbest.cn/):** Interact with our models online and in our local web demo environments.
*   **Easy Inference:** Integrate our models with popular tools like llama.cpp, Ollama, and vLLM for efficient deployment.

**Learn More:**

*   [Model Zoo](#model-zoo)
*   [Inference](#inference)
*   [Fine-tuning](#fine-tuning)
*   [FAQs](#faqs)

**[Check out the GitHub repo for detailed documentation, code, and more!](https://github.com/OpenBMB/MiniCPM-V)**