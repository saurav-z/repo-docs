<div align="center">
  <img src="docs/source/_static/img/et-logo.png" alt="ExecuTorch Logo" width="200">
  <h1>ExecuTorch: The Ultimate On-Device AI Framework</h1>
</div>

<div align="center">
  <a href="https://github.com/pytorch/executorch/graphs/contributors"><img src="https://img.shields.io/github/contributors/pytorch/executorch?style=for-the-badge&color=blue" alt="Contributors"></a>
  <a href="https://github.com/pytorch/executorch/stargazers"><img src="https://img.shields.io/github/stars/pytorch/executorch?style=for-the-badge&color=blue" alt="Stargazers"></a>
  <a href="https://discord.gg/Dh43CKSAdc"><img src="https://img.shields.io/badge/Discord-Join%20Us-purple?logo=discord&logoColor=white&style=for-the-badge" alt="Join our Discord community"></a>
  <a href="https://pytorch.org/executorch/main/index"><img src="https://img.shields.io/badge/Documentation-000?logo=googledocs&logoColor=FFE165&style=for-the-badge" alt="Check out the documentation"></a>
  <hr>
</div>

ExecuTorch, developed by PyTorch, is a powerful, open-source framework designed for blazing-fast on-device inference and training, revolutionizing AI experiences across various platforms. **[Explore the ExecuTorch GitHub Repository](https://github.com/pytorch/executorch)**.

## Key Features

*   **Cross-Platform Compatibility:** Runs seamlessly on iOS, macOS (ARM64), Android, Linux, and microcontrollers, enabling broad device support.
*   **Hardware Acceleration:** Optimizes performance across a wide range of hardware, including Apple, Arm, Cadence, MediaTek, NXP, OpenVINO, Qualcomm, Vulkan, and XNNPACK.
*   **Broad Model Support:** Supports a diverse range of models, including LLMs (Large Language Models), CV (Computer Vision), ASR (Automatic Speech Recognition), and TTS (Text-to-Speech).
*   **End-to-End Solution:** Provides a complete workflow from PyTorch model authoring to deployment and debugging, streamlining the development process.
*   **Lightweight Runtime:** Delivers high-performance experiences by leveraging a lightweight runtime, fully utilizing the hardware capabilities of CPUs, NPUs, and DSPs.
*   **Accelerated Performance:** Provides exceptional speed and efficiency for both inference and training tasks directly on the device.

## Getting Started

Ready to deploy your AI models? Check out these resources to begin:

*   **Step-by-Step Tutorial:** Get ExecuTorch up and running locally and deploy a model to your device: [https://pytorch.org/executorch/stable/getting-started.html](https://pytorch.org/executorch/stable/getting-started.html)
*   **Colab Notebook:** Experiment with ExecuTorch instantly: [https://colab.research.google.com/drive/1qpxrXC3YdJQzly3mRg-4ayYiOjC6rue3?usp=sharing](https://colab.research.google.com/drive/1qpxrXC3YdJQzly3mRg-4ayYiOjC6rue3?usp=sharing)
*   **LLM Examples:** Dive into specific open-source LLM use cases:
    *   [Llama](examples/models/llama/README.md)
    *   [Qwen 3](examples/models/qwen3/README.md)
    *   [Phi-4-mini](examples/models/phi_4_mini/README.md)
    *   [Llava](examples/models/llava/README.md)

## Join the Community

We value your feedback!

*   **Discussion Board:** Share your thoughts and questions: [https://github.com/pytorch/executorch/discussions](https://github.com/pytorch/executorch/discussions)
*   **Discord:** Connect with the community in real time: [https://discord.gg/Dh43CKSAdc](https://discord.gg/Dh43CKSAdc)

## Contribute

Your contributions are welcome! Please review the [CONTRIBUTING.md](CONTRIBUTING.md) guidelines and chat with us on [Discord](https://discord.gg/Dh43CKSAdc).

## Directory Structure

Refer to the [Codebase structure](CONTRIBUTING.md#codebase-structure) section of the [Contributing Guidelines](CONTRIBUTING.md) for details.

## License

ExecuTorch is licensed under the BSD license, found in the [LICENSE](LICENSE) file.