<div align="center">
  <img src="docs/source/_static/img/et-logo.png" alt="ExecuTorch Logo" width="200">
  <h1>ExecuTorch: The Ultimate On-Device AI Framework</h1>
</div>

<div align="center">
  <a href="https://github.com/pytorch/executorch/graphs/contributors"><img src="https://img.shields.io/github/contributors/pytorch/executorch?style=for-the-badge&color=blue" alt="Contributors"></a>
  <a href="https://github.com/pytorch/executorch/stargazers"><img src="https://img.shields.io/github/stars/pytorch/executorch?style=for-the-badge&color=blue" alt="Stargazers"></a>
  <a href="https://discord.gg/Dh43CKSAdc"><img src="https://img.shields.io/badge/Discord-Join%20Us-purple?logo=discord&logoColor=white&style=for-the-badge" alt="Join our Discord community"></a>
  <a href="https://pytorch.org/executorch/main/index"><img src="https://img.shields.io/badge/Documentation-000?logo=googledocs&logoColor=FFE165&style=for-the-badge" alt="Check out the documentation"></a>
  <hr>
</div>

**ExecuTorch** empowers developers to deploy and run high-performance AI models directly on various devices, from smartphones to microcontrollers, enabling seamless on-device experiences.  Learn more about ExecuTorch on [GitHub](https://github.com/pytorch/executorch).

## Key Features of ExecuTorch

*   **Broad Platform Support:** Compatible with iOS, macOS (ARM64), Android, Linux, and Microcontrollers, offering unparalleled flexibility.
*   **Hardware Acceleration:** Optimizes performance by leveraging hardware capabilities including Apple, Arm, Cadence, MediaTek, NXP, OpenVINO, Qualcomm, Vulkan, and XNNPACK.
*   **Model Compatibility:** Supports a wide array of AI models, including Large Language Models (LLMs), Computer Vision (CV), Automatic Speech Recognition (ASR), and Text-to-Speech (TTS), making it ideal for diverse applications.
*   **Portability:** Enables deployment across a wide variety of platforms, from high-end mobile phones to embedded systems and microcontrollers.
*   **Productivity:** Streamlines development with familiar PyTorch toolchains, facilitating model authoring, conversion, debugging, and deployment.
*   **Performance:** Provides a seamless and high-performance user experience through a lightweight runtime and efficient hardware utilization.

## Getting Started with ExecuTorch

Explore the following resources to quickly get started with ExecuTorch:

*   **Step-by-Step Tutorial:** [Visit the tutorial](https://pytorch.org/executorch/stable/getting-started.html) to set up your local environment and deploy a model to a device.
*   **Colab Notebook:**  Experiment with ExecuTorch directly in your browser using this [Colab Notebook](https://colab.research.google.com/drive/1qpxrXC3YdJQzly3mRg-4ayYiOjC6rue3?usp=sharing).
*   **LLM Examples:** Jump into LLM use cases with specific instructions for popular open-source models:
    *   [Llama](examples/models/llama/README.md)
    *   [Qwen 3](examples/models/qwen3/README.md)
    *   [Phi-4-mini](examples/models/phi_4_mini/README.md)
    *   [Llava](examples/models/llava/README.md)

## Engage with the ExecuTorch Community

We value your feedback and contributions.

*   **Discussion Board:** Share your ideas and ask questions on the [Discussion Board](https://github.com/pytorch/executorch/discussions).
*   **Discord:** Join our real-time chat on [Discord](https://discord.gg/Dh43CKSAdc) to connect with the community.

## Contributing to ExecuTorch

We welcome contributions from the community! Please review the [contribution guidelines](CONTRIBUTING.md) and connect with us on [Discord](https://discord.gg/Dh43CKSAdc) to get involved.

## Directory Structure

For detailed information on the codebase structure, please refer to the [Codebase structure](CONTRIBUTING.md#codebase-structure) section of the [Contributing Guidelines](CONTRIBUTING.md).

## License

ExecuTorch is released under the BSD license.  See the [LICENSE](LICENSE) file for details.