<div align="center">
  <img src="docs/source/_static/img/et-logo.png" alt="ExecuTorch Logo" width="200">
  <h1>ExecuTorch: The Ultimate On-Device AI Framework</h1>
</div>

<div align="center">
  <a href="https://github.com/pytorch/executorch/graphs/contributors"><img src="https://img.shields.io/github/contributors/pytorch/executorch?style=for-the-badge&color=blue" alt="Contributors"></a>
  <a href="https://github.com/pytorch/executorch/stargazers"><img src="https://img.shields.io/github/stars/pytorch/executorch?style=for-the-badge&color=blue" alt="Stargazers"></a>
  <a href="https://discord.gg/Dh43CKSAdc"><img src="https://img.shields.io/badge/Discord-Join%20Us-purple?logo=discord&logoColor=white&style=for-the-badge" alt="Join our Discord community"></a>
  <a href="https://pytorch.org/executorch/main/index"><img src="https://img.shields.io/badge/Documentation-000?logo=googledocs&logoColor=FFE165&style=for-the-badge" alt="Check out the documentation"></a>
  <hr>
</div>

ExecuTorch is a powerful, open-source framework from Meta for efficient on-device AI inference and training, enabling cutting-edge AI experiences directly on your devices.  **(See the original repository on GitHub: [pytorch/executorch](https://github.com/pytorch/executorch))**

## Key Features

*   **Comprehensive Platform Support:** Runs on a wide range of operating systems, including iOS, macOS (ARM64), Android, Linux, and even microcontrollers.
*   **Broad Hardware Acceleration:** Optimized for various hardware accelerators like Apple, Arm, Cadence, MediaTek, OpenVINO, Qualcomm, Vulkan, and XNNPACK, maximizing performance.
*   **Versatile Model Support:** Compatible with a broad spectrum of AI models, including LLMs (Large Language Models), CV (Computer Vision), ASR (Automatic Speech Recognition), and TTS (Text-to-Speech).
*   **Portability:** Enables compatibility across diverse computing platforms, from high-end mobile phones to constrained embedded systems.
*   **Productivity:** Leverages familiar PyTorch toolchains for model authoring, conversion, debugging, and deployment, streamlining the development workflow.
*   **Performance:** Delivers a seamless, high-performance user experience through a lightweight runtime, utilizing full hardware capabilities such as CPUs, NPUs, and DSPs.

## Getting Started

Explore these resources to begin using ExecuTorch:

*   [Step-by-Step Tutorial](https://pytorch.org/executorch/stable/getting-started.html): Get up and running locally and deploy a model to a device.
*   [Colab Notebook](https://colab.research.google.com/drive/1qpxrXC3YdJQzly3mRg-4ayYiOjC6rue3?usp=sharing): Experiment with ExecuTorch directly in your browser.
*   LLM Example Guides: Follow instructions for specific open-source models, including:
    *   [Llama](examples/models/llama/README.md)
    *   [Qwen 3](examples/models/qwen3/README.md)
    *   [Phi-4-mini](examples/models/phi_4_mini/README.md)
    *   [Llava](examples/models/llava/README.md)

## Feedback and Engagement

We value your contributions and insights. Join the community and share your feedback:

*   [Discussion Board](https://github.com/pytorch/executorch/discussions): Share your thoughts, ask questions, and engage with other users.
*   [Discord](https://discord.gg/Dh43CKSAdc): Chat with us in real-time and get support from the community.

## Contributing

Help us improve ExecuTorch!  Review the [CONTRIBUTING guidelines](CONTRIBUTING.md) and connect with us on [Discord](https://discord.gg/Dh43CKSAdc) to get started.

## Directory Structure

Refer to the [Codebase structure](CONTRIBUTING.md#codebase-structure) section of the [Contributing Guidelines](CONTRIBUTING.md) for more details.

## License

ExecuTorch is BSD licensed, as found in the LICENSE file.