<div align="center">
  <img src="docs/source/_static/img/et-logo.png" alt="ExecuTorch Logo" width="200">
  <h1>ExecuTorch: High-Performance On-Device AI for Everyone</h1>
</div>

<div align="center">
  <a href="https://github.com/pytorch/executorch/graphs/contributors"><img src="https://img.shields.io/github/contributors/pytorch/executorch?style=for-the-badge&color=blue" alt="Contributors"></a>
  <a href="https://github.com/pytorch/executorch/stargazers"><img src="https://img.shields.io/github/stars/pytorch/executorch?style=for-the-badge&color=blue" alt="Stargazers"></a>
  <a href="https://discord.gg/Dh43CKSAdc"><img src="https://img.shields.io/badge/Discord-Join%20Us-purple?logo=discord&logoColor=white&style=for-the-badge" alt="Join our Discord community"></a>
  <a href="https://pytorch.org/executorch/main/index"><img src="https://img.shields.io/badge/Documentation-000?logo=googledocs&logoColor=FFE165&style=for-the-badge" alt="Check out the documentation"></a>
  <hr>
</div>

ExecuTorch empowers developers to run state-of-the-art AI models directly on devices, providing a seamless and high-performance experience.  Developed by Meta, ExecuTorch drives on-device AI across platforms like Facebook, Instagram, Meta Quest, and more.  [Learn more at the original repository](https://github.com/pytorch/executorch).

## Key Features

*   **Wide Model Support:** Compatible with a broad range of models, including LLMs (Large Language Models), CV (Computer Vision), ASR (Automatic Speech Recognition), and TTS (Text to Speech).
*   **Cross-Platform Compatibility:** Supports a vast array of operating systems, including iOS, macOS (ARM64), Android, Linux, and microcontrollers.
*   **Hardware Acceleration:** Leverages hardware acceleration on platforms like Apple, Arm, Cadence, MediaTek, OpenVINO, Qualcomm, Vulkan, and XNNPACK for optimized performance.
*   **Portability:** Runs on devices from high-end mobile phones to embedded systems.
*   **Productivity:** Uses familiar PyTorch toolchains for model authoring, conversion, debugging, and deployment.
*   **Performance:** Delivers a lightweight runtime with full hardware utilization for optimal speed.

## Getting Started

Get started with ExecuTorch quickly by:

*   Following the [Step-by-Step Tutorial](https://pytorch.org/executorch/stable/getting-started.html) to run locally and deploy a model.
*   Using this [Colab Notebook](https://colab.research.google.com/drive/1qpxrXC3YdJQzly3mRg-4ayYiOjC6rue3?usp=sharing) to experiment.
*   Exploring LLM examples for [Llama](examples/models/llama/README.md), [Qwen 3](examples/models/qwen3/README.md), [Phi-4-mini](examples/models/phi_4_mini/README.md), and [Llava](examples/models/llava/README.md).

## Feedback and Engagement

We value your feedback and invite you to share suggestions and bug reports via the [Discussion Board](https://github.com/pytorch/executorch/discussions) or chat in real-time on [Discord](https://discord.gg/Dh43CKSAdc).

## Contributing

We welcome contributions! Review the [guidelines](CONTRIBUTING.md) and connect with us on [Discord](https://discord.gg/Dh43CKSAdc) to get involved.

## Directory Structure

Refer to the [Codebase structure](CONTRIBUTING.md#codebase-structure) section of the [Contributing Guidelines](CONTRIBUTING.md) for detailed information.

## License

ExecuTorch is licensed under the BSD License (see the LICENSE file).