<div align="center">
  <img src="docs/source/_static/img/et-logo.png" alt="ExecuTorch Logo" width="200">
  <h1>ExecuTorch: Powering the Future of On-Device AI</h1>
</div>

<div align="center">
  <a href="https://github.com/pytorch/executorch/graphs/contributors"><img src="https://img.shields.io/github/contributors/pytorch/executorch?style=for-the-badge&color=blue" alt="Contributors"></a>
  <a href="https://github.com/pytorch/executorch/stargazers"><img src="https://img.shields.io/github/stars/pytorch/executorch?style=for-the-badge&color=blue" alt="Stargazers"></a>
  <a href="https://discord.gg/Dh43CKSAdc"><img src="https://img.shields.io/badge/Discord-Join%20Us-purple?logo=discord&logoColor=white&style=for-the-badge" alt="Join our Discord community"></a>
  <a href="https://pytorch.org/executorch/main/index"><img src="https://img.shields.io/badge/Documentation-000?logo=googledocs&logoColor=FFE165&style=for-the-badge" alt="Check out the documentation"></a>
  <hr>
</div>

**ExecuTorch** is a powerful, open-source framework from PyTorch for efficient on-device AI inference and training, enabling innovative AI experiences across a wide range of platforms.  Learn more and contribute on [GitHub](https://github.com/pytorch/executorch).

## Key Features and Benefits

ExecuTorch delivers a seamless and high-performance experience for AI models on diverse devices, from high-end mobile phones to microcontrollers, with the following key advantages:

*   **Broad Platform Support:** Compatible with iOS, macOS (ARM64), Android, Linux, and microcontrollers.
*   **Extensive Hardware Acceleration:** Optimized for Apple, Arm, Cadence, MediaTek, NXP, OpenVINO, Qualcomm, Vulkan, and XNNPACK.
*   **Model Versatility:** Supports a wide range of models including LLMs (Large Language Models), CV (Computer Vision), ASR (Automatic Speech Recognition), and TTS (Text to Speech).
*   **Portability:**  Runs on a wide variety of computing platforms, from high-end mobile phones to highly constrained embedded systems and microcontrollers.
*   **Productivity:** Uses the same toolchains and developer tools from PyTorch model authoring and conversion, to debugging and deployment on diverse platforms.
*   **Performance:** A lightweight runtime utilizes full hardware capabilities like CPUs, NPUs, and DSPs for a seamless and high-performance experience.

## Getting Started

Quickly deploy and run your AI models with these resources:

*   **Step-by-Step Tutorial:**  Get started locally and deploy a model to a device: [Step by Step Tutorial](https://pytorch.org/executorch/stable/getting-started.html)
*   **Interactive Colab Notebook:** Experiment with ExecuTorch directly in your browser: [Colab Notebook](https://colab.research.google.com/drive/1qpxrXC3YdJQzly3mRg-4ayYiOjC6rue3?usp=sharing)
*   **LLM Examples:** Explore pre-configured setups for popular open-source models such as [Llama](examples/models/llama/README.md), [Qwen 3](examples/models/qwen3/README.md), [Phi-4-mini](examples/models/phi_4_mini/README.md), and [Llava](examples/models/llava/README.md)

## Community and Contribution

We encourage community participation to enhance ExecuTorch.

*   **Join the Discussion:** Share your thoughts, ask questions, and report issues on the [Discussion Board](https://github.com/pytorch/executorch/discussions).
*   **Connect on Discord:** Engage in real-time discussions with developers and users: [Discord](https://discord.gg/Dh43CKSAdc).
*   **Contribute:** Review the [guidelines](CONTRIBUTING.md) and contribute to the project.

## Directory Structure

See the [Codebase structure](CONTRIBUTING.md#codebase-structure) section of the [Contributing Guidelines](CONTRIBUTING.md) for details.

## License

ExecuTorch is licensed under the BSD license.  See the `LICENSE` file for details.