<div align="center">
  <img src="docs/source/_static/img/et-logo.png" alt="ExecuTorch Logo" width="200">
  <h1 align="center">ExecuTorch: On-Device AI Framework for Inference and Training</h1>
</div>

<div align="center">
  <a href="https://github.com/pytorch/executorch/graphs/contributors"><img src="https://img.shields.io/github/contributors/pytorch/executorch?style=for-the-badge&color=blue" alt="Contributors"></a>
  <a href="https://github.com/pytorch/executorch/stargazers"><img src="https://img.shields.io/github/stars/pytorch/executorch?style=for-the-badge&color=blue" alt="Stargazers"></a>
  <a href="https://discord.gg/Dh43CKSAdc"><img src="https://img.shields.io/badge/Discord-Join%20Us-purple?logo=discord&logoColor=white&style=for-the-badge" alt="Join our Discord community"></a>
  <a href="https://pytorch.org/executorch/main/index"><img src="https://img.shields.io/badge/Documentation-000?logo=googledocs&logoColor=FFE165&style=for-the-badge" alt="Check out the documentation"></a>
  <hr>
</div>

ExecuTorch is a powerful, end-to-end framework enabling on-device AI experiences, trusted by Meta and powering applications across Facebook, Instagram, and more.  Learn more on the [original repository](https://github.com/pytorch/executorch).

## Key Features

ExecuTorch offers a comprehensive solution for on-device AI, providing:

*   **Versatile Platform Support:**
    *   **Operating Systems:** iOS, macOS (ARM64), Android, Linux, and Microcontrollers.
    *   **Hardware Acceleration:** Apple, Arm, Cadence, MediaTek, OpenVINO, Qualcomm, Vulkan, and XNNPACK.
*   **Broad Model Compatibility:** Supports a wide range of AI models, including Large Language Models (LLMs), Computer Vision (CV), Automatic Speech Recognition (ASR), and Text-to-Speech (TTS).
*   **Portability:** Enables deployment across diverse computing platforms, from high-end mobile phones to embedded systems.
*   **Productivity:** Utilizes the same toolchains and developer tools from PyTorch for model authoring, conversion, debugging, and deployment.
*   **Performance:** Delivers a seamless and high-performance user experience through a lightweight runtime that leverages hardware capabilities like CPUs, NPUs, and DSPs.

## Getting Started

Quickly deploy and experiment with ExecuTorch using these resources:

*   [Step-by-Step Tutorial](https://pytorch.org/executorch/stable/getting-started.html): Get started locally and deploy a model to a device.
*   [Colab Notebook](https://colab.research.google.com/drive/1qpxrXC3YdJQzly3mRg-4ayYiOjC6rue3?usp=sharing): Start experimenting right away with a Colab Notebook.
*   LLM Examples: Specific instructions for popular open-source models such as [Llama](examples/models/llama/README.md), [Qwen 3](examples/models/qwen3/README.md), [Phi-4-mini](examples/models/phi_4_mini/README.md), and [Llava](examples/models/llava/README.md)

## Feedback and Engagement

We encourage community feedback and contributions to improve ExecuTorch.

*   [Discussion Board](https://github.com/pytorch/executorch/discussions)
*   [Discord Community](https://discord.gg/Dh43CKSAdc)

## Contributing

Join us in building the future of on-device AI!

*   Review the [Contributing Guidelines](CONTRIBUTING.md).
*   Connect with us on [Discord](https://discord.gg/Dh43CKSAdc).

## Directory Structure

Refer to the [Codebase structure](CONTRIBUTING.md#codebase-structure) section of the [Contributing Guidelines](CONTRIBUTING.md) for details.

## License

ExecuTorch is licensed under the BSD license, available in the [LICENSE](LICENSE) file.