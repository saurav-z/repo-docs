<div align="center">
  <img src="docs/source/_static/img/et-logo.png" alt="ExecuTorch Logo" width="200">
  <h1>ExecuTorch: Powering On-Device AI for a Seamless Experience</h1>
</div>

<div align="center">
  <a href="https://github.com/pytorch/executorch/graphs/contributors"><img src="https://img.shields.io/github/contributors/pytorch/executorch?style=for-the-badge&color=blue" alt="Contributors"></a>
  <a href="https://github.com/pytorch/executorch/stargazers"><img src="https://img.shields.io/github/stars/pytorch/executorch?style=for-the-badge&color=blue" alt="Stargazers"></a>
  <a href="https://discord.gg/Dh43CKSAdc"><img src="https://img.shields.io/badge/Discord-Join%20Us-purple?logo=discord&logoColor=white&style=for-the-badge" alt="Join our Discord community"></a>
  <a href="https://pytorch.org/executorch/main/index"><img src="https://img.shields.io/badge/Documentation-000?logo=googledocs&logoColor=FFE165&style=for-the-badge" alt="Check out the documentation"></a>
  <hr>
</div>

**ExecuTorch** is a cutting-edge, open-source framework from PyTorch designed to enable high-performance on-device AI experiences. Learn more about ExecuTorch on its [GitHub Repository](https://github.com/pytorch/executorch).

## Key Features of ExecuTorch

*   **Broad Model Support:**  Works with a wide range of models including LLMs (Large Language Models), Computer Vision (CV), Automatic Speech Recognition (ASR), and Text to Speech (TTS).
*   **Cross-Platform Compatibility:**  Supports diverse operating systems, including iOS, macOS (ARM64), Android, Linux, and even Microcontrollers.
*   **Hardware Acceleration:** Leverages the full power of various hardware, including Apple, Arm, Cadence, MediaTek, OpenVINO, Qualcomm, Vulkan, and XNNPACK, for optimal performance.
*   **Portability:**  Designed to run across a wide array of devices, from high-end mobile phones to resource-constrained embedded systems.
*   **Developer Productivity:**  Offers a unified toolchain, streamlining the process from PyTorch model creation and conversion to debugging and deployment.
*   **High Performance:** Provides a lightweight runtime that utilizes hardware capabilities such as CPUs, NPUs, and DSPs, ensuring a seamless user experience.

## Getting Started with ExecuTorch

Ready to experience the power of on-device AI with ExecuTorch?

*   Follow the [Step-by-Step Tutorial](https://pytorch.org/executorch/stable/getting-started.html) to get started.
*   Experiment using the [Colab Notebook](https://colab.research.google.com/drive/1qpxrXC3YdJQzly3mRg-4ayYiOjC6rue3?usp=sharing).
*   Explore LLM use cases with specific instructions for models like [Llama](examples/models/llama/README.md), [Qwen 3](examples/models/qwen3/README.md), [Phi-4-mini](examples/models/phi_4_mini/README.md), and [Llava](examples/models/llava/README.md).

## Feedback and Community

We welcome your contributions and feedback. Engage with the ExecuTorch community through:

*   [Discussion Board](https://github.com/pytorch/executorch/discussions)
*   [Discord](https://discord.gg/Dh43CKSAdc)

## Contributing to ExecuTorch

Interested in contributing to ExecuTorch?  Review the [contribution guidelines](CONTRIBUTING.md) and connect with the community on [Discord](https://discord.gg/Dh43CKSAdc).

## Directory Structure

Refer to the [Codebase Structure](CONTRIBUTING.md#codebase-structure) section of the [Contributing Guidelines](CONTRIBUTING.md) for detailed information.

## License

ExecuTorch is licensed under the BSD license. See the [LICENSE](LICENSE) file for details.