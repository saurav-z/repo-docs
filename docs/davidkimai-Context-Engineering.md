# Context Engineering: Beyond Prompt Engineering

**Unlock the next level of AI potential by mastering context design, orchestration, and optimization. Dive into the principles and visuals that define the future of language model interaction at [davidkimai/Context-Engineering](https://github.com/davidkimai/Context-Engineering).**

Context Engineering moves beyond prompt engineering to control everything else the model sees, including examples, memory, retrieval, tools, state, and control flow.

## Key Features

*   **First-Principles Approach:** A progressive guide to context design, built around a biological metaphor for clarity and understanding.
*   **Practical Tutorials:** Hands-on guides with example code to experiment with context expansion, control loops, and more.
*   **Reusable Templates:** Ready-to-use components to accelerate your context engineering projects.
*   **Deep Dive Documentation:** Detailed documentation covering token budgeting, retrieval systems, evaluation metrics, and more.
*   **Cutting-Edge Research:** Integration of the latest research on memory, reasoning, and emergent symbolic mechanisms.

## The Problem: From Prompt Engineering to Context Design

Prompt engineering focuses on *what you say* (single instruction), while context engineering focuses on *everything else the model sees*. This repo is all about the **entire context window** that surrounds those prompts.

## What You'll Learn

| Concept | What It Is | Why It Matters |
|---------|------------|----------------|
| **Token Budget** | Optimizing every token in your context | More tokens = more $$ and slower responses |
| **Few-Shot Learning** | Teaching by showing examples | Often works better than explanation alone |
| **Memory Systems** | Persisting information across turns | Enables stateful, coherent interactions |
| **Retrieval Augmentation** | Finding & injecting relevant documents | Grounds responses in facts, reduces hallucination |
| **Control Flow** | Breaking complex tasks into steps | Solve harder problems with simpler prompts |
| **Context Pruning** | Removing irrelevant information | Keep only what's necessary for performance |
| **Metrics & Evaluation** | Measuring context effectiveness | Iterative optimization of token use vs. quality |
| **Cognitive Tools & Prompt Programming** | Learm to build custom tools and templates | Prompt programming enables new layers for context engineering |
| **Neural Field Theory** | Context as a Neural Field | Modeling context as a dynamic neural field allows for iterative context updating |
| **Symbolic Mechanisms** | Symbolic architectures enable higher order reasoning | Smarter systems = less work |
| **Quantum Semantics** |  Meaning as observer-dependent  | Design context systems leveraging superpositional techniques |

## Getting Started

1.  **Understand the Fundamentals:** Start with `00_foundations/01_atoms_prompting.md` for a quick overview.
2.  **Experiment:** Run the minimal prompt example at `10_guides_zero_to_one/01_min_prompt.py`.
3.  **Build:** Copy and paste context examples, and leverage `20_templates/minimal_context.yaml` in your own projects.
4.  **Explore:** Study the complete example at `30_examples/00_toy_chatbot/`

## Research and Applications

This repository incorporates the latest research from IBM Zurich, Princeton, MIT, and others. It is built around the following metaphors:

*   **Atoms → Molecules → Cells → Organs → Neural Systems → Neural & Semantic Field Theory**
*   **Single Prompt → Few-shot → Memory + Agents → Multi-agents → Cognitive Tools + Operating Systems → Context = Fields + Persistence & Resonance**

## Star History
[![Star History Chart](https://api.star-history.com/svg?repos=davidkimai/Context-Engineering&type=Date)](https://www.star-history.com/#davidkimai/Context-Engineering&Date)

## Contribution and License

Contributions are welcome! See the [CONTRIBUTING.md](.github/CONTRIBUTING.md) for details. This project is licensed under the [MIT License](LICENSE).