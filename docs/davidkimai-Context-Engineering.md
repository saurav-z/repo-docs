# Context Engineering: The Definitive Guide to Maximizing LLM Performance

**Unlock the full potential of Large Language Models (LLMs) by mastering context engineering – the art and science of crafting optimal information payloads.**  [Explore the original repository](https://github.com/davidkimai/Context-Engineering).

**Key Features:**

*   **First-Principles Approach:** Dive deep into the foundational concepts of context design and optimization.
*   **Progressive Learning Path:**  Navigate a structured learning journey, from basic prompt engineering to advanced techniques like neural field theory and emergent symbolic mechanisms.
*   **Hands-on Tutorials:**  Experiment with code and practical examples using Jupyter Notebooks
*   **Comprehensive Documentation:**  Explore detailed guides on token budgeting, retrieval systems, evaluation metrics, and more.
*   **Community Collaboration:**  Benefit from community contributions and actively participate in the development of cutting-edge techniques.
*   **Links to Latest Research:** Stay on top of the emerging science of LLMs with links to cutting-edge research on memory, cognitive tools, and emergent symbols.

## What is Context Engineering?

Context engineering goes beyond basic prompt design to encompass *everything* the LLM sees during inference: examples, memory, retrieval, tools, and control flow. This comprehensive approach allows you to significantly enhance the performance and capabilities of your LLM applications.

```
                    Prompt Engineering  │  Context Engineering
                       ↓                │            ↓                      
               "What you say"           │  "Everything else the model sees"
             (Single instruction)       │    (Examples, memory, retrieval,
                                        │     tools, state, control flow)
```

### Definition of Context Engineering

> **Context is not just the single prompt users send to an LLM. Context is the complete information payload provided to a LLM at inference time, encompassing all structured informational components that the model needs to plausibly accomplish a given task.**
>
> — [**Definition of Context Engineering from A Systematic Analysis of Over 1400 Research Papers**](https://arxiv.org/pdf/2507.13334)

## Why Learn Context Engineering?

Mastering context engineering empowers you to:

*   **Achieve Higher Performance:**  Optimize LLM outputs for improved accuracy and relevance.
*   **Unlock New Capabilities:**  Build advanced applications with features like memory, reasoning, and tool integration.
*   **Reduce Costs:**  Optimize token usage for more efficient and cost-effective LLM interactions.
*   **Stay Ahead of the Curve:**  Learn the latest techniques and research in the rapidly evolving field of LLMs.

## Core Concepts & Roadmap

This repository provides a structured learning path organized into:

**Level 1: Foundations**

*   Atoms:  Single Instructions and prompts
*   Molecules: Few-shot Examples
*   Cells: Persistent Memory
*   Organs: Multi-step Flows
*   Cognitive Tools: Reasoning frameworks
*   Advanced Applications: Real-world implementations

**Level 2: Field Theory**

*   Neural Systems: Reasoning frameworks
*   Neural Fields: Continuous meaning
*   Persistence and Resonance: Field dynamics and attractors

**Level 3: Protocol Systems**

*   Protocol Shells: Structured templates
*   Unified Systems: Protocol Integration

**Level 4: Meta-Recursion**

*   Meta-Recursive Framework

## The Structure

The repository offers:

*   **Foundations:** Core concepts, starting with basic prompting and progressing to advanced techniques.
*   **Guides:** Hands-on tutorials.
*   **Templates:** Reusable components for building your own projects.
*   **Examples:** Practical implementations.
*   **Reference:** Deep-dive documentation.
*   **Protocols:** Frameworks for structuring tasks.
*   **Agents:** Agent demonstrations.
*   **Field Integration:** Complete field projects.
*   **Cognitive Tools**: Reasoning System

## Key Learning Areas:

*   **Token Budgeting:** Optimize token usage.
*   **Few-Shot Learning:** Teach through examples.
*   **Memory Systems:** Enable stateful interactions.
*   **Retrieval Augmentation:** Ground responses in facts.
*   **Control Flow:** Create step-by-step solutions.
*   **Context Pruning:** Keep only necessary information.
*   **Metrics & Evaluation:** Measure effectiveness.
*   **Cognitive Tools:** Build custom tools and templates.
*   **Neural Field Theory:** Model context as a dynamic field.
*   **Symbolic Mechanisms:** Enable advanced reasoning.
*   **Quantum Semantics:** Explore superpositional techniques.

## Research Highlights & Evidence

Stay up-to-date with the latest advancements in LLM technology:

### **MEM1: Memory + Reasoning**

Learn to train AI agents to keep only what matters through the merging of memory and reasoning at every step. [See details from the Singapore-MIT research](https://www.arxiv.org/pdf/2506.15841).

### **Cognitive Tools**

Explore how "Cognitive tools" encapsulate reasoning operations within the LLM itself to help it reason and do complex tasks. [Read the research from IBM Zurich](https://www.arxiv.org/pdf/2506.12115).

### **Emergent Symbols**

Learn how LLMs develop their own inner symbolic “logic circuits”—enabling them to reason with abstract variables. See what [ICML Princeton](https://openreview.net/forum?id=y1SnRPDWx4) has to say.

## Additional Resources

*   [DeepWiki - Context Engineering](https://deepwiki.com/davidkimai/Context-Engineering)
*   [DeepGraph](https://www.deepgraph.co/davidkimai/Context-Engineering)
*   [Chat with NotebookLM + Podcast Deep Dive](https://notebooklm.google.com/notebook/0c6e4dc6-9c30-4f53-8e1a-05cc9ff3bc7e)
*   [Discord](https://discord.gg/JeFENHNNNQ)

## Contributing

We welcome contributions!  See [CONTRIBUTING.md](.github/CONTRIBUTING.md) for guidelines.

## License

This project is licensed under the [MIT License](LICENSE).

## Citation

```bibtex
@misc{context-engineering,
  author = {Context Engineering Contributors},
  title = {Context Engineering: Beyond Prompt Engineering},
  year = {2025},
  publisher = {GitHub},
  url = {https://github.com/davidkimai/context-engineering}
}
```

## Acknowledgements

This repository is inspired by the work of [Andrej Karpathy](https://x.com/karpathy/status/1937902205765607626) and the open-source community.