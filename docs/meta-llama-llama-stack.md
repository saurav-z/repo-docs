# Llama Stack: Build AI Applications Faster with a Unified API

Llama Stack provides a streamlined approach to AI application development, unifying APIs and simplifying the deployment of your Llama-based applications; check out the original repository at [https://github.com/meta-llama/llama-stack](https://github.com/meta-llama/llama-stack).

## Key Features

*   **Unified API Layer:** Access inference, RAG, agents, tools, safety features, evaluations, and telemetry through a single, consistent API.
*   **Plugin Architecture:** Supports a wide range of API implementations across local development, on-premises, cloud, and mobile environments.
*   **Prepackaged Distributions:** Get started quickly and reliably with verified distributions for various deployment scenarios.
*   **Multiple Developer Interfaces:** Utilize CLI tools, Python, Typescript, iOS, and Android SDKs.
*   **Example Applications:** Leverage standalone applications as blueprints for production-ready AI solutions.
*   **Llama 4 Support:** Seamlessly integrate and run the latest Llama 4 models.

## Get Started Quickly

Install Llama Stack with a single command:

```bash
curl -LsSf https://github.com/meta-llama/llama-stack/raw/main/install.sh | bash
```

## Overview

Llama Stack simplifies AI application development by standardizing core building blocks and codifying best practices within the Llama ecosystem. It offers a flexible and consistent experience for developers, enabling them to build, test, and deploy AI applications across diverse infrastructure choices.

## Benefits of Using Llama Stack

*   **Flexible Infrastructure:** Choose your preferred infrastructure without changing your APIs, with flexible deployment options.
*   **Consistent Application Behavior:** Build, test, and deploy AI applications with unified APIs and consistent behavior.
*   **Robust Ecosystem:** Integrated with various distribution partners for tailored infrastructure, software, and services for deploying Llama models.

## API Providers & Distributions

Llama Stack supports a growing list of API providers and distributions. See the [full list](https://llama-stack.readthedocs.io/en/latest/providers/index.html) and supported distributions in the original repository for comprehensive details.

## Client SDKs

Integrate with Llama Stack using SDKs for popular programming languages:

*   **Python:** [llama-stack-client-python](https://github.com/meta-llama/llama-stack-client-python)
*   **Swift:** [llama-stack-client-swift](https://github.com/meta-llama/llama-stack-client-swift)
*   **Typescript:** [llama-stack-client-typescript](https://github.com/meta-llama/llama-stack-client-typescript)
*   **Kotlin:** [llama-stack-client-kotlin](https://github.com/meta-llama/llama-stack-client-kotlin)

## Documentation

Find detailed information in the documentation, including:

*   [Quick Start](https://llama-stack.readthedocs.io/en/latest/getting_started/index.html)
*   [CLI References](https://llama-stack.readthedocs.io/en/latest/references/index.html)
*   [Getting Started Guide](https://llama-stack.readthedocs.io/en/latest/getting_started/index.html)
*   [Contributing Guide](CONTRIBUTING.md)