<picture>
  <source media="(prefers-color-scheme: dark)" srcset="./assets/banner.jpg">
  <source media="(prefers-color-scheme: light)" srcset="./assets/banner.jpg">
  <img alt="Open-LLM-VTuber Banner" src="./assets/banner.jpg">
</picture>

<h1 align="center">Open-LLM-VTuber: Your AI Companion Comes to Life</h1>

<h3 align="center">
  [![GitHub release](https://img.shields.io/github/v/release/t41372/Open-LLM-VTuber)](https://github.com/t41372/Open-LLM-VTuber/releases)
  [![License](https://img.shields.io/github/license/t41372/Open-LLM-VTuber)](https://github.com/t41372/Open-LLM-VTuber/blob/master/LICENSE)
  [![CodeQL](https://github.com/Open-LLM-VTuber/Open-LLM-VTuber/actions/workflows/codeql.yml/badge.svg)](https://github.com/Open-LLM-VTuber/Open-LLM-VTuber/actions/workflows/codeql.yml)
  [![Ruff](https://github.com/Open-LLM-VTuber/Open-LLM-VTuber/actions/workflows/ruff.yml/badge.svg)](https://github.com/Open-LLM-VTuber/Open-LLM-VTuber/actions/workflows/ruff.yml)
  [![Docker](https://img.shields.io/badge/t41372%2FOpen--LLM--VTuber-%25230db7ed.svg?logo=docker&logoColor=blue&labelColor=white&color=blue)](https://hub.docker.com/r/t41372/open-llm-vtuber)
  [![QQ Group](https://img.shields.io/badge/QQ_Group-792615362-white?style=flat&logo=qq&logoColor=white)](https://qm.qq.com/q/ngvNUQpuKI)
  [![QQ Channel](https://img.shields.io/badge/QQ_Channel_(dev)-pd93364606-white?style=flat&logo=qq&logoColor=white)](https://pd.qq.com/s/tt54r3bu)
  [![BuyMeACoffee](https://img.shields.io/badge/Buy%20Me%20a%20Coffee-ffdd00?style=for-the-badge&logo=buy-me-a-coffee&logoColor=black)](https://www.buymeacoffee.com/yi.ting)
  [![](https://dcbadge.limes.pink/api/server/3UDA8YFDXx)](https://discord.gg/3UDA8YFDXx)
  [![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/Open-LLM-VTuber/Open-LLM-VTuber)
  [English README](https://github.com/t41372/Open-LLM-VTuber/blob/main/README.md) | [中文README](https://github.com/t41372/Open-LLM-VTuber/blob/main/README.CN.md)
  [Documentation](https://open-llm-vtuber.github.io/docs/quick-start) | [![Roadmap](https://img.shields.io/badge/Roadmap-GitHub_Project-yellow)](https://github.com/orgs/Open-LLM-VTuber/projects/2)
  <a href="https://trendshift.io/repositories/12358" target="_blank"><img src="https://trendshift.io/api/badge/repositories/12358" alt="t41372%2FOpen-LLM-VTuber | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"/></a>
</h3>

<p align="center"><b>Bring your AI companion to life with real-time voice interaction, visual perception, and a captivating Live2D avatar!</b></p>

> :warning: This project is under **active development**.

## Key Features

*   **Cross-Platform Compatibility:** Runs seamlessly on Windows, macOS, and Linux.
*   **Offline Mode:** Enjoy privacy and security with local model support, eliminating the need for internet access.
*   **Interactive Web & Desktop Clients:** Experience feature-rich interactions and personalized settings in both web and desktop environments. Desktop client supports a special transparent background desktop pet mode, allowing the AI companion to accompany you anywhere on your screen.
*   **Advanced Interaction:**
    *   Visual Perception (camera, screen recording, screenshots).
    *   Microphone-Free Voice Interruption.
    *   Touch Feedback.
    *   Live2D Expression Control.
    *   Desktop Pet Mode.
    *   AI Inner Thoughts Display.
    *   Proactive AI Speaking.
    *   Chat Log Persistence.
    *   TTS Translation Support.
*   **Extensive Model Support:** Compatible with a wide range of Large Language Models (LLMs), Automatic Speech Recognition (ASR) and Text-to-Speech (TTS) solutions.
*   **Highly Customizable:** Modify configurations, import custom Live2D models, and even implement custom Agent architectures.

### Demo

| ![](assets/i1.jpg) | ![](assets/i2.jpg) |
|:---:|:---:|
| ![](assets/i3.jpg) | ![](assets/i4.jpg) |

## Getting Started

Dive in! Find installation instructions and quick start guides in the [Quick Start](https://open-llm-vtuber.github.io/docs/quick-start) section of our documentation.

## Updates

*   Update via `uv run update.py` if you installed any versions later than `v1.0.0`.

## Uninstall

*   Most files (dependencies, models) are stored in the project folder.
*   Models downloaded via ModelScope/Hugging Face may be in `MODELSCOPE_CACHE` or `HF_HOME`.
*   Review the installation guide for removal of optional tools (`uv`, `ffmpeg`, `deeplx`, etc.).

## Contribute

Help us build the future!  Check out the [development guide](https://docs.llmvtuber.com/docs/development-guide/overview).

## Related Projects

*   [ylxmf2005/LLM-Live2D-Desktop-Assitant](https://github.com/ylxmf2005/LLM-Live2D-Desktop-Assitant) - Your Live2D desktop assistant powered by LLM! Available for both Windows and MacOS, it senses your screen, retrieves clipboard content, and responds to voice commands with a unique voice. Featuring voice wake-up, singing capabilities, and full computer control for seamless interaction with your favorite character.

## Third-Party Licenses

### Live2D Sample Models Notice

This project includes Live2D sample models provided by Live2D Inc. These assets are licensed separately under the Live2D Free Material License Agreement and the Terms of Use for Live2D Cubism Sample Data. They are not covered by the MIT license of this project.

*   For commercial use, ensure you have the appropriate permissions from Live2D Inc.

## Contributors

Thank you to all the contributors!

<a href="https://github.com/Open-LLM-VTuber/Open-LLM-VTuber/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=Open-LLM-VTuber/Open-LLM-VTuber" />
</a>

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=t41372/open-llm-vtuber&type=Date)](https://star-history.com/#t41372/open-llm-vtuber&Date)

---

**[Get Started with Open-LLM-VTuber](https://github.com/Open-LLM-VTuber/Open-LLM-VTuber)**