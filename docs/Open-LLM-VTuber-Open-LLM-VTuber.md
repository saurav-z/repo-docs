<div align="center">
  <img src="./assets/banner.jpg" alt="Open-LLM-VTuber Banner">
</div>

<h1 align="center">Open-LLM-VTuber: Your AI Companion Comes to Life</h1>

<div align="center">
  <p>Create a voice-interactive AI companion with a Live2D avatar that you can run offline!</p>
  <p>
    <a href="https://github.com/t41372/Open-LLM-VTuber" target="_blank">
      <img src="https://img.shields.io/github/stars/t41372/Open-LLM-VTuber?style=social" alt="GitHub Stars">
    </a>
    <a href="https://github.com/t41372/Open-LLM-VTuber" target="_blank">View on GitHub</a> |
    <a href="https://open-llm-vtuber.github.io/docs/quick-start" target="_blank">Documentation</a> |
    <a href="https://github.com/orgs/Open-LLM-VTuber/projects/2" target="_blank">Roadmap</a>
  </p>
</div>

---

**Open-LLM-VTuber** transforms the way you interact with AI, offering a unique and immersive experience by combining real-time voice conversations, visual perception, and a captivating Live2D avatar. Bring your ideal AI companion to life‚Äîwhether it's a virtual friend, a supportive partner, or a fun pet‚Äîall running locally on your computer!

<br>

## ‚ú® Key Features

*   **Cross-Platform Compatibility:** Seamlessly runs on Windows, macOS, and Linux, supporting NVIDIA and non-NVIDIA GPUs and CPU fallback.
*   **Offline Mode:** Converse with your AI companion securely, without an internet connection, ensuring complete privacy.
*   **Versatile Clients:** Enjoy interactive features through both web and desktop client modes, including a unique transparent background desktop pet mode.
*   **Advanced Interaction:**
    *   Visual perception via camera, screen recording, and screenshots.
    *   Voice interruption and touch feedback.
    *   Live2D expression control & pet mode with click-through and global top-most settings.
    *   Proactive speaking, AI thought display, and chat log persistence.
    *   TTS translation support.
*   **Extensive Model Support:** Wide range of LLMs (Ollama, OpenAI, Gemini, Claude, Mistral, and more), ASR (sherpa-onnx, Faster-Whisper, etc.), and TTS (sherpa-onnx, Coqui-TTS, Bark, etc.) options.
*   **Highly Customizable:**
    *   Easy module configuration.
    *   Character customization, allowing you to import Live2D models and modify prompts.
    *   Flexible Agent implementations.
    *   Modular design for easy integration of new LLMs, ASR, TTS, and more.

<br>

## üöÄ Quick Start

Get started by following the detailed [Quick Start Guide](https://open-llm-vtuber.github.io/docs/quick-start) in our documentation.

<br>

## üì£ Updates & Contributing

*   **Breaking Changes:** Be aware of breaking changes in v1.0.0; consult the [quick start guide](https://open-llm-vtuber.github.io/docs/quick-start) for updating.
*   **Contribution:** Eager to help? Check out the [development guide](https://docs.llmvtuber.com/docs/development-guide/overview).

<br>

## üìú Third-Party Licenses
This project uses sample Live2D models licensed separately under the Live2D Free Material License Agreement. Ensure compliance for commercial use. See the original README for more details.

<br>

## üôè Contributors
Thank you to all the contributors who have helped make this project possible!

<a href="https://github.com/Open-LLM-VTuber/Open-LLM-VTuber/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=Open-LLM-VTuber/Open-LLM-VTuber" />
</a>

<br>

## üåü Star History

[![Star History Chart](https://api.star-history.com/svg?repos=t41372/open-llm-vtuber&type=Date)](https://star-history.com/#t41372/open-llm-vtuber&Date)