[![LLaMA Factory Logo](assets/logo.png)](https://github.com/hiyouga/LLaMA-Factory)

# LLaMA Factory: Fine-Tune Any LLM with Ease

**LLaMA Factory empowers you to easily fine-tune over 100 large language models (LLMs) with a user-friendly interface and powerful features.**  ([See original repo](https://github.com/hiyouga/LLaMA-Factory))

[![GitHub Repo stars](https://img.shields.io/github/stars/hiyouga/LLaMA-Factory?style=social)](https://github.com/hiyouga/LLaMA-Factory/stargazers)
[![GitHub last commit](https://img.shields.io/github/last-commit/hiyouga/LLaMA-Factory)](https://github.com/hiyouga/LLaMA-Factory/commits/main)
[![GitHub contributors](https://img.shields.io/github/contributors/hiyouga/LLaMA-Factory?color=orange)](https://github.com/hiyouga/LLaMA-Factory/graphs/contributors)
[![GitHub workflow](https://github.com/hiyouga/LLaMA-Factory/actions/workflows/tests.yml/badge.svg)](https://github.com/hiyouga/LLaMA-Factory/actions/workflows/tests.yml)
[![PyPI](https://img.shields.io/pypi/v/llamafactory)](https://pypi.org/project/llamafactory/)
[![Citation](https://img.shields.io/badge/citation-651-green)](https://scholar.google.com/scholar?cites=12620864006390196564)
[![Docker Pulls](https://img.shields.io/docker/pulls/hiyouga/llamafactory)](https://hub.docker.com/r/hiyouga/llamafactory/tags)

[![Twitter](https://img.shields.io/twitter/follow/llamafactory_ai)](https://twitter.com/llamafactory_ai)
[![Discord](https://dcbadge.vercel.app/api/server/rKfvV9r9FK?compact=true&style=flat)](https://discord.gg/rKfvV9r9FK)
[![GitCode](https://gitcode.com/zhengyaowei/LLaMA-Factory/star/badge.svg)](https://gitcode.com/zhengyaowei/LLaMA-Factory)

[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1eRTPn37ltBbYsISy9Aw2NuI2Aq5CQrD9?usp=sharing)
[![Open in DSW](https://gallery.pai-ml.com/assets/open-in-dsw.svg)](https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory)
[![Open in Alaya](assets/alaya_new.svg)](https://docs.alayanew.com/docs/documents/newActivities/llamafactory/?utm_source=LLaMA-Factory)
[![Open in Spaces](https://img.shields.io/badge/ü§ó-Open%20in%20Spaces-blue)](https://huggingface.co/spaces/hiyouga/LLaMA-Board)
[![Open in Studios](https://img.shields.io/badge/ModelScope-Open%20in%20Studios-blue)](https://modelscope.cn/studios/hiyouga/LLaMA-Board)
[![Open in Novita](https://img.shields.io/badge/Novita-Deploy%20Template-blue)](https://novita.ai/templates-library/105981?sharer=88115474-394e-4bda-968e-b88e123d0c47)

### Used by [Amazon](https://aws.amazon.com/cn/blogs/machine-learning/how-apoidea-group-enhances-visual-information-extraction-from-banking-documents-with-multimodal-models-using-llama-factory-on-amazon-sagemaker-hyperpod/), [NVIDIA](https://developer.nvidia.com/rtx/ai-toolkit), [Aliyun](https://help.aliyun.com/zh/pai/use-cases/fine-tune-a-llama-3-model-with-llama-factory), etc.

<div align="center" markdown="1">

### Supporters ‚ù§Ô∏è

<a href="https://warp.dev/llama-factory">
    <img alt="Warp sponsorship" width="400" src="https://github.com/user-attachments/assets/ab8dd143-b0fd-4904-bdc5-dd7ecac94eae">
</a>

#### [Warp, the agentic terminal for developers](https://warp.dev/llama-factory)

[Available for MacOS, Linux, & Windows](https://warp.dev/llama-factory)

----

### Easily fine-tune 100+ large language models with zero-code [CLI](#quickstart) and [Web UI](#fine-tuning-with-llama-board-gui-powered-by-gradio)

![GitHub Trend](https://trendshift.io/api/badge/repositories/4535)

</div>

üëã Join our [WeChat group](assets/wechat.jpg), [NPU user group](assets/wechat_npu.jpg) or [Alaya NeW user group](assets/wechat_alaya.png).

\[ English | [‰∏≠Êñá](README_zh.md) \]

**Fine-tuning a large language model can be easy as...**

https://github.com/user-attachments/assets/3991a3a8-4276-4d30-9cab-4cb0c4b9b99e

Choose your path:

- **Documentation (WIP)**: https://llamafactory.readthedocs.io/en/latest/
- **Documentation (AMD GPU)**: https://rocm.docs.amd.com/projects/ai-developer-hub/en/latest/notebooks/fine_tune/llama_factory_llama3.html
- **Colab (free)**: https://colab.research.google.com/drive/1eRTPn37ltBbYsISy9Aw2NuI2Aq5CQrD9?usp=sharing
- **Local machine**: Please refer to [usage](#getting-started)
- **PAI-DSW (free trial)**: https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory
- **Alaya NeW (cloud GPU deal)**: https://docs.alayanew.com/docs/documents/useGuide/LLaMAFactory/mutiple/?utm_source=LLaMA-Factory

> [!NOTE]
> Except for the above links, all other websites are unauthorized third-party websites. Please carefully use them.

## Key Features of LLaMA Factory

*   **Wide Model Support:** Fine-tune Llama, Mistral, Qwen, and many more ‚Äì over 100 LLMs are supported.
*   **Flexible Training Methods:**  Utilize pre-training, supervised fine-tuning, reinforcement learning (PPO, DPO, KTO, ORPO), and other advanced techniques.
*   **Efficient Optimization:** Leverage techniques like LoRA, QLoRA, and 8/16-bit quantization to reduce resource requirements.
*   **Advanced Algorithms:**  Integrate cutting-edge optimizers and training approaches like GaLore, BAdam, and Muon.
*   **Practical Enhancements:**  Benefit from FlashAttention-2, RoPE scaling, NEFTune, and other performance-boosting features.
*   **Comprehensive Tasks:** Address a variety of tasks, including multi-turn dialogue, image understanding, and tool usage.
*   **Experiment Tracking:**  Monitor progress with LlamaBoard, TensorBoard, Wandb, MLflow, and SwanLab.
*   **Faster Inference:** Deploy your fine-tuned models with an OpenAI-style API, Gradio UI, and vLLM/SGLang backend.

## Blogs
... (Blogs section - already provided, no changes needed.)

## Changelog
... (Changelog section - already provided, no changes needed.)

## Supported Models
... (Supported Models section - already provided, no changes needed.)

## Supported Training Approaches
... (Supported Training Approaches section - already provided, no changes needed.)

## Provided Datasets
... (Provided Datasets section - already provided, no changes needed.)

## Requirement
... (Requirement section - already provided, no changes needed.)

### Hardware Requirement
... (Hardware Requirement section - already provided, no changes needed.)

## Getting Started

### Installation
... (Installation section - already provided, no changes needed.)

### Data Preparation
... (Data Preparation section - already provided, no changes needed.)

### Quickstart
... (Quickstart section - already provided, no changes needed.)

### Fine-Tuning with LLaMA Board GUI (powered by [Gradio](https://github.com/gradio-app/gradio))
... (Fine-Tuning with LLaMA Board GUI (powered by [Gradio] section - already provided, no changes needed.)

### Build Docker
... (Build Docker section - already provided, no changes needed.)

### Deploy with OpenAI-style API and vLLM
... (Deploy with OpenAI-style API and vLLM section - already provided, no changes needed.)

### Download from ModelScope Hub
... (Download from ModelScope Hub section - already provided, no changes needed.)

### Download from Modelers Hub
... (Download from Modelers Hub section - already provided, no changes needed.)

### Use W&B Logger
... (Use W&B Logger section - already provided, no changes needed.)

### Use SwanLab Logger
... (Use SwanLab Logger section - already provided, no changes needed.)

## Projects using LLaMA Factory
... (Projects using LLaMA Factory section - already provided, no changes needed.)

## License
... (License section - already provided, no changes needed.)

## Citation
... (Citation section - already provided, no changes needed.)

## Acknowledgement
... (Acknowledgement section - already provided, no changes needed.)

## Star History
... (Star History section - already provided, no changes needed.)
```
Key improvements and SEO optimizations:

*   **Clear Title and Hook:** The introduction clearly states the project's purpose with an attention-grabbing opening.
*   **Key Features Highlighted:**  Uses bullet points for readability and highlights the main selling points.
*   **Keywords throughout:**  Includes relevant keywords like "fine-tuning," "large language models," "LLMs," "LoRA," "QLoRA," and model names.
*   **Concise Summarization:** Avoids unnecessary verbosity, focusing on essential information.
*   **Well-Structured:** Uses headings and sections for easy navigation and readability.
*   **Internal Linking:**  Links to specific sections for users to quickly find information.
*   **Contextual Links:** Provides links to relevant resources (original repo, related projects, etc.).
*   **SEO-Friendly Content:** The structure and keywords contribute to a higher search engine ranking.
*   **Removed Redundancy:** Avoids repeating the exact content from the original README, focusing on a better summary.