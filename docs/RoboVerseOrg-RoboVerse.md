<p align="center">
  <img src="docs/source/_static/RoboVerse86.22.svg" width="50%" alt="RoboVerse">
</p>

<p align="center">
  <img src="docs/source/metasim/images/tea.jpg" alt="RoboVerse Overview" width="50%">
</p>

<p align="center">
  <a href="https://roboverseorg.github.io"><img src="https://img.shields.io/badge/project-page-brightgreen" alt="Project Page"></a>
  <a href="https://arxiv.org/abs/2504.18904"><img src="https://img.shields.io/badge/paper-preprint-red" alt="Paper"></a>
  <a href="https://roboverse.wiki"><img src="https://img.shields.io/badge/doc-page-orange" alt="Documentation"></a>
  <a href="https://github.com/RoboVerseOrg/RoboVerse/issues"><img src="https://img.shields.io/github/issues/RoboVerseOrg/RoboVerse?color=yellow" alt="Issues"></a>
  <a href="https://github.com/RoboVerseOrg/RoboVerse/discussions"><img src="https://img.shields.io/github/discussions/RoboVerseOrg/RoboVerse?color=blueviolet" alt="Discussions"></a>
  <a href="https://discord.gg/6e2CPVnAD3"><img src="https://img.shields.io/discord/1356345436927168552?logo=discord&color=blue" alt="Discord"></a>
  <a href="docs/source/_static/wechat.jpg"><img src="https://img.shields.io/badge/wechat-QR_code-green" alt="WeChat"></a>
</p>

## RoboVerse: The Unified Platform for Scalable and Generalizable Robot Learning

RoboVerse provides a comprehensive platform, dataset, and benchmark designed to accelerate the development of scalable and generalizable robot learning.  ([See the original repository](https://github.com/RoboVerseOrg/RoboVerse))

**Key Features:**

*   **Unified Platform:** A central hub for robot learning research, providing a standardized environment for experimentation.
*   **Extensive Dataset:** Includes a rich and diverse dataset to facilitate robust model training and evaluation.
*   **Benchmarking Tools:** Offers standardized benchmarks for evaluating and comparing robot learning algorithms.
*   **Modular Design:** Designed to be easily extensible and adaptable to new simulators, tasks, and workflows.
*   **Active Community:** Open-source with a welcoming community, encouraging contributions and feedback.

## News

*   **[2025-04-10]** RoboVerse gets accepted by RSS 2025!
*   **[2025-04-03]** Code released! This codebase is actively evolving, and contributions are encouraged!

## Getting Started

Dive into RoboVerse with the following resources:

*   **Documentation:**  [https://roboverse.wiki/metasim/#](https://roboverse.wiki/metasim/#)
*   **Tutorials:** [https://roboverse.wiki/metasim/get_started/quick_start/0_static_scene](https://roboverse.wiki/metasim/get_started/quick_start/0_static_scene)

## Contributing

We welcome contributions!  See [CONTRIBUTING.md](./CONTRIBUTING.md) for details on how to contribute to RoboVerse.

## Wish List & Feature Requests

Have a feature request? Share it in the Wish List section of our [GitHub Discussions](https://github.com/RoboVerseOrg/RoboVerse/discussions/categories/wish-list).  Upvote the requests you find most relevant!

## License and Acknowledgments

RoboVerse is licensed under the Apache License 2.0.

RoboVerse utilizes the following simulation frameworks, renderers, and libraries: (list provided in original README)

RoboVerse also integrates data from the following projects: (list provided in original README)

The licenses for the assets used in RoboVerse will be added soon. Please contact us if you have any issues.

## Citation

If you find RoboVerse useful, please cite it using the following BibTeX entry:

```bibtex
@misc{geng2025roboverse,
      title={RoboVerse: Towards a Unified Platform, Dataset and Benchmark for Scalable and Generalizable Robot Learning},
      author={Haoran Geng and Feishi Wang and Songlin Wei and Yuyang Li and Bangjun Wang and Boshi An and Charlie Tianyue Cheng and Haozhe Lou and Peihao Li and Yen-Jen Wang and Yutong Liang and Dylan Goetting and Chaoyi Xu and Haozhe Chen and Yuxi Qian and Yiran Geng and Jiageng Mao and Weikang Wan and Mingtong Zhang and Jiangran Lyu and Siheng Zhao and Jiazhao Zhang and Jialiang Zhang and Chengyang Zhao and Haoran Lu and Yufei Ding and Ran Gong and Yuran Wang and Yuxuan Kuang and Ruihai Wu and Baoxiong Jia and Carlo Sferrazza and Hao Dong and Siyuan Huang and Yue Wang and Jitendra Malik and Pieter Abbeel},
      year={2025},
      eprint={2504.18904},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2504.18904},
}