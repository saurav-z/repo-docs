<p align="center">
  <img src="docs/source/_static/RoboVerse86.22.svg" width="50%" alt="RoboVerse">
</p>

<p align="center">
  <a href="https://roboverseorg.github.io"><img src="https://img.shields.io/badge/project-page-brightgreen" alt="Project Page"></a>
  <a href="https://arxiv.org/abs/2504.18904"><img src="https://img.shields.io/badge/paper-preprint-red" alt="Paper"></a>
  <a href="https://roboverse.wiki"><img src="https://img.shields.io/badge/doc-page-orange" alt="Documentation"></a>
  <a href="https://github.com/RoboVerseOrg/RoboVerse/issues"><img src="https://img.shields.io/github/issues/RoboVerseOrg/RoboVerse?color=yellow" alt="Issues"></a>
  <a href="https://github.com/RoboVerseOrg/RoboVerse/discussions"><img src="https://img.shields.io/github/discussions/RoboVerseOrg/RoboVerse?color=blueviolet" alt="Discussions"></a>
  <a href="https://discord.gg/6e2CPVnAD3"><img src="https://img.shields.io/discord/1356345436927168552?logo=discord&color=blue" alt="Discord"></a>
  <a href="docs/source/_static/wechat.jpg"><img src="https://img.shields.io/badge/wechat-QR_code-green" alt="WeChat"></a>
</p>

# RoboVerse: A Unified Platform for Scalable and Generalizable Robot Learning

RoboVerse is a comprehensive platform offering a unified environment, dataset, and benchmark for advancing robot learning. **Explore the future of robotics by diving into the RoboVerse project, available on [GitHub](https://github.com/RoboVerseOrg/RoboVerse).**

## Key Features

*   **Unified Platform:** RoboVerse provides a consistent framework for robot learning research.
*   **Extensive Dataset:** The platform integrates data from various sources to facilitate learning.
*   **Benchmark for Evaluation:** Offers a standardized benchmark to assess and compare robot learning algorithms.
*   **Open Source and Community Driven:** The codebase welcomes contributions and feedback from the open-source community.
*   **Integration of Multiple Simulators:** Supports popular simulation frameworks for diverse research applications.

## Getting Started

To get started with RoboVerse, please refer to the detailed [documentation](https://roboverse.wiki/metasim/#). Detailed [tutorials](https://roboverse.wiki/metasim/get_started/quick_start/0_static_scene) are also available.

## How to Contribute

We welcome contributions! Please consult [CONTRIBUTING.md](./CONTRIBUTING.md) for instructions on how to contribute to RoboVerse.

## Feature Requests and Wish List

Share your ideas and suggestions! Post feature requests and upvote your favorite ideas in the Wish List section of our [GitHub Discussions](https://github.com/RoboVerseOrg/RoboVerse/discussions/categories/wish-list).

## License and Acknowledgments

RoboVerse is licensed under the Apache License 2.0.

The project leverages the following simulation frameworks, renderers, and libraries:

*   Isaac Lab
*   Isaac Gym
*   MuJoCo
*   SAPIEN
*   PyBullet
*   Genesis
*   cuRobo
*   PyRep
*   Blender

RoboVerse integrates data from these projects:

*   RLBench
*   Maniskill
*   LIBERO
*   Meta-World
*   robosuite
*   GraspNet
*   ARNOLD
*   GAPartNet
*   GAPartManip
*   UniDoorManip
*   SimplerEnv
*   RLAfford
*   Open6DOR
*   CALVIN
*   GarmentLab
*   Matterport3D
*   VLN-CE
*   vMaterials
*   HumanoidBench

## Citation

If you use RoboVerse in your research, please cite it using the following BibTeX entry:

```bibtex
@misc{geng2025roboverse,
      title={RoboVerse: Towards a Unified Platform, Dataset and Benchmark for Scalable and Generalizable Robot Learning}, 
      author={Haoran Geng and Feishi Wang and Songlin Wei and Yuyang Li and Bangjun Wang and Boshi An and Charlie Tianyue Cheng and Haozhe Lou and Peihao Li and Yen-Jen Wang and Yutong Liang and Dylan Goetting and Chaoyi Xu and Haozhe Chen and Yuxi Qian and Yiran Geng and Jiageng Mao and Weikang Wan and Mingtong Zhang and Jiangran Lyu and Siheng Zhao and Jiazhao Zhang and Jialiang Zhang and Chengyang Zhao and Haoran Lu and Yufei Ding and Ran Gong and Yuran Wang and Yuxuan Kuang and Ruihai Wu and Baoxiong Jia and Carlo Sferrazza and Hao Dong and Siyuan Huang and Yue Wang and Jitendra Malik and Pieter Abbeel},
      year={2025},
      eprint={2504.18904},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2504.18904}, 
}