[![Project Status: Active -- The project has reached a stable, usable state and is being actively developed.](http://www.repostatus.org/badges/latest/active.svg)](http://www.repostatus.org/#active)
[![Documentation](https://readthedocs.com/projects/nvidia-nemo/badge/?version=main)](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/main/)
[![CodeQL](https://github.com/nvidia/nemo/actions/workflows/codeql.yml/badge.svg?branch=main&event=push)](https://github.com/nvidia/nemo/actions/workflows/codeql.yml)
[![NeMo core license and license for collections in this repo](https://img.shields.io/badge/License-Apache%202.0-brightgreen.svg)](https://github.com/NVIDIA/NeMo/blob/master/LICENSE)
[![Release version](https://badge.fury.io/py/nemo-toolkit.svg)](https://badge.fury.io/py/nemo-toolkit)
[![Python version](https://img.shields.io/pypi/pyversions/nemo-toolkit.svg)](https://badge.fury.io/py/nemo-toolkit)
[![PyPi total downloads](https://static.pepy.tech/personalized-badge/nemo-toolkit?period=total&units=international_system&left_color=grey&right_color=brightgreen&left_text=downloads)](https://pepy.tech/project/nemo-toolkit)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

# NVIDIA NeMo: Revolutionizing Generative AI with Scalable, Cloud-Native Frameworks

[NVIDIA NeMo](https://github.com/NVIDIA/NeMo) is your all-in-one solution for building, customizing, and deploying cutting-edge generative AI models across LLMs, MMs, ASR, TTS, and Computer Vision domains.

## Key Features

*   **Large Language Models (LLMs):** Train, fine-tune, and deploy state-of-the-art LLMs.
*   **Multimodal Models (MMs):** Develop models that understand and generate content across multiple modalities (text, images, video).
*   **Automatic Speech Recognition (ASR):** Build and optimize ASR models for accurate speech-to-text transcription.
*   **Text-to-Speech (TTS):** Create high-quality, natural-sounding speech from text.
*   **Computer Vision (CV):** Leverage pre-trained models and tools for various computer vision tasks.
*   **Modular Architecture:** NeMo 2.0 introduces a modular, Python-based configuration for greater flexibility and control.
*   **Scalability:** Train models on thousands of GPUs with seamless integration with NeMo-Run for efficient large-scale experiments.
*   **Cutting-Edge Techniques:** Utilize advanced training techniques like Tensor Parallelism, Pipeline Parallelism, FSDP, MoE, and mixed precision.
*   **Integration with NVIDIA Ecosystem:** Leverage NVIDIA Transformer Engine, Megatron Core, and Riva for optimal performance and deployment.
*   **Hugging Face Support:** NeMo framework's latest feature AutoModel enables broad support for Hugging Face models.
*   **Cosmos Support:** NeMo Framework now supports training and customizing the NVIDIA Cosmos collection of world foundation models.

## What's New

*   **NeMo 2.0 Release:** Enhanced modularity, ease of use, and scalability with a Python-based configuration.
*   **Blackwell Support:** Performance benchmarks on GB200 & B200.
*   **New Model Support:** Expanded support for community models, including Llama 4, Flux, Llama Nemotron, Hyena & Evo2, Qwen2-VL, Qwen2.5, Gemma3, Qwen3-30B&32B.
*   **Hugging Face Models Support:** Pretrain and finetune Hugging Face models via AutoModel.
*   **Cosmos Integration:** Accelerate custom video foundation model pipelines with NeMo Curator.

## Getting Started

*   **Quickstart:** [NeMo 2.0 Quickstart](https://docs.nvidia.com/nemo-framework/user-guide/latest/nemo-2.0/quickstart.html)
*   **User Guide:** [NeMo Framework User Guide](https://docs.nvidia.com/nemo-framework/user-guide/latest/playbooks/index.html)
*   **Pre-trained Models:** Explore pre-trained models on [Hugging Face Hub](https://huggingface.co/models?library=nemo&sort=downloads&search=nvidia) and [NVIDIA NGC](https://catalog.ngc.nvidia.com/models?query=nemo&orderBy=weightPopularDESC).

## Installation

Choose your preferred method:

*   **Conda / Pip:** Install for exploring NeMo. Recommended for ASR and TTS.
*   **NGC PyTorch Container:** Install from source in a highly optimized container.
*   **NGC NeMo Container:** Ready-to-go, high-performance solution.

**For detailed installation instructions, please refer to the "Install NeMo Framework" section in the original [README](https://github.com/NVIDIA/NeMo).**

## Contributing

We welcome community contributions!  See [CONTRIBUTING.md](https://github.com/NVIDIA/NeMo/blob/stable/CONTRIBUTING.md) for details.

## Resources

*   **Developer Documentation:** [Latest Documentation](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/main/)
*   **Publications:** [Publications](https://nvidia.github.io/NeMo/publications/)
*   **Discussions:** [Discussions Board](https://github.com/NVIDIA/NeMo/discussions)
*   **Blogs:** See the expanding list of blogs in the original [README](https://github.com/NVIDIA/NeMo).

## License

NeMo is licensed under the [Apache License 2.0](https://github.com/NVIDIA/NeMo?tab=Apache-2.0-1-ov-file).
```

Key improvements and SEO considerations:

*   **Clear, Concise Hook:**  A strong opening sentence immediately explains what NeMo is.
*   **Keyword Optimization:** Uses key terms like "generative AI," "LLMs," "MMs," "ASR," "TTS," "Computer Vision," and "NVIDIA."
*   **Structured Headings:** Improves readability and SEO by clearly organizing information.
*   **Bulleted Key Features:** Highlights the most important selling points of the framework.
*   **Concise Summaries:**  The content is distilled to be more easily scanned.
*   **Call to Action:** Encourages exploration and contributions.
*   **Internal Linking:** Links to key resources within the documentation.
*   **External Linking:** Links to Hugging Face and NGC.
*   **Clear Installation Instructions:**  Highlights the different install methods.
*   **Removed Redundancy:** Removed redundant links and repetitive information.
*   **Focus on Value:** Showcases the benefits of using NeMo.