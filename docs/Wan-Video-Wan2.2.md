# Wan2.2: Unleash Cinematic Video Generation with Open-Source AI 

**Wan2.2** introduces a groundbreaking open-source video generation model, empowering users with advanced features for creating stunning, high-quality videos. Learn more and explore the source code on [GitHub](https://github.com/Wan-Video/Wan2.2).

## Key Features

*   **Mixture-of-Experts (MoE) Architecture:** Leverages MoE, enhancing the model's capacity without increasing computational costs.  The MoE allows for specialized experts to handle different stages of the denoising process, improving overall video quality.
*   **Cinematic Aesthetics:** Incorporates meticulously curated aesthetic data, allowing for precise control over lighting, composition, and color, enabling cinematic-level video generation.
*   **Enhanced Motion Generation:** Trained on significantly expanded datasets, leading to improved generalization in motion, semantics, and aesthetics, achieving top performance.
*   **Efficient High-Definition TI2V:** Includes a 5B model optimized for fast 720P video generation, running efficiently on consumer-grade GPUs. This model supports text-to-video and image-to-video generation.
*   **User-Friendly Integration:**  Seamlessly integrates with popular platforms like ComfyUI and Diffusers for easy access and experimentation.

## What's New?

*   **Open-Source and Accessible:** Inference code and model weights are released.
*   **Hugging Face Integration:**  Models are available on Hugging Face Spaces, with integration to popular libraries like ComfyUI and Diffusers.
*   **Rapid Development:**  Constant updates and optimizations, including integration with the latest technologies.

## Quick Start: Run Wan2.2

**(See original README for detailed steps including installation and running code)**

*   **Installation:** Clone the repo and install dependencies.
*   **Model Download:** Download the desired model from Hugging Face or ModelScope.
*   **Generation:** Utilize the provided scripts to generate videos using text-to-video (T2V), image-to-video (I2V), or text-image-to-video (TI2V) modes.

## Additional Information

*   **Latest News:** (See original README for the most recent updates).
*   **Community Works:** Explore projects and research built on Wan2.1 and Wan2.2 (e.g., DiffSynth-Studio and Kijai's ComfyUI WanVideoWrapper).
*   **Todo List:** (See original README)
*   **Computational Efficiency:** Explore the table showing the efficiency of different Wan2.2 models on various GPUs.
*   **Introduction of Wan2.2:** Detailed technical information on the MoE architecture, high-compression TI2V model, and performance comparisons.
*   **Citation:** If you use Wan2.2, please cite the paper.
*   **License Agreement:**  Wan2.2 is licensed under the Apache 2.0 License.  Review the license for details on usage and restrictions.
*   **Acknowledgements:** (See original README)
*   **Contact Us:** Join our Discord or WeChat groups for support and updates.