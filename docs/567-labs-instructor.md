# Instructor: Effortlessly Extract Structured Data from LLMs

**Simplify LLM interactions and get reliable JSON outputs with Instructor, a Python library built on Pydantic for robust data validation, type safety, and seamless integration with major LLM providers.**  Learn more and explore the codebase at [https://github.com/567-labs/instructor](https://github.com/567-labs/instructor).

[![PyPI](https://img.shields.io/pypi/v/instructor?style=flat-square)](https://pypi.org/project/instructor/)
[![Downloads](https://img.shields.io/pypi/dm/instructor?style=flat-square)](https://pypi.org/project/instructor/)
[![GitHub Stars](https://img.shields.io/github/stars/instructor-ai/instructor?style=flat-square)](https://github.com/instructor-ai/instructor)
[![Discord](https://img.shields.io/discord/1192334452110659664?style=flat-square)](https://discord.gg/bD9YE9JArw)
[![Twitter](https://img.shields.io/twitter/follow/jxnlco?style=flat-square)](https://twitter.com/jxnlco)

## Key Features

*   **Simplified Data Extraction:**  Eliminate the complexities of manual JSON parsing, error handling, and retries.
*   **Pydantic Integration:** Leverage the power of Pydantic for data validation, type safety, and IDE support, ensuring data integrity.
*   **Automatic Retries:** Automatically retry extractions when validation fails, improving reliability.
*   **Streaming Support:** Get partial objects in real-time as they are generated by the LLM, enhancing responsiveness.
*   **Nested Object Support:** Easily extract complex, nested data structures with minimal effort.
*   **Cross-Provider Compatibility:** Use the same code with various LLM providers, including OpenAI, Anthropic, Google, and local models.
*   **Production-Ready:** Proven in production by thousands of developers and companies.

## The Problem Instructor Solves

Extracting structured data from LLMs can be cumbersome and error-prone, often requiring:

*   Writing complex JSON schemas
*   Handling validation errors
*   Implementing retry mechanisms
*   Parsing unstructured responses
*   Adapting to different provider APIs

**Instructor streamlines this process with a simple, intuitive interface:**

| Without Instructor                             | With Instructor                               |
| :--------------------------------------------- | :-------------------------------------------- |
| ```python                                      | ```python                                      |
| response = openai.chat.completions.create(     | client = instructor.from_provider("openai/gpt-4") |
|   model="gpt-4",                               |                                               |
|   messages=[{"role": "user", "content": "..."}],| user = client.chat.completions.create(          |
|   tools=[                                      |   response_model=User,                          |
|       {                                         |   messages=[{"role": "user", "content": "..."}],|
|           "type": "function",                  | )                                               |
|           "function": {                         |                                               |
|               "name": "extract_user",          | # That's it! user is validated and typed        |
|               "parameters": {                   | ```                                             |
|                   "type": "object",             |                                               |
|                   "properties": {               |                                               |
|                       "name": {"type": "string"},|                                               |
|                       "age": {"type": "integer"},|                                               |
|                   },                              |                                               |
|               },                                |                                               |
|           },                                    |                                               |
|       }                                         |                                               |
|   ],                                            |                                               |
| )                                               |                                               |
|                                                |                                               |
| # Parse response                               |                                               |
| tool_call = response.choices[0].message.tool_calls[0]|                                             |
| user_data = json.loads(tool_call.function.arguments)|                                             |
|                                                |                                               |
| # Validate manually                           |                                               |
| if "name" not in user_data:                    |                                               |
|     # Handle error...                          |                                               |
|     pass                                        |                                               |
| ```                                             |                                               |

## Installation

Get started in seconds:

```bash
pip install instructor
```

Or use your preferred package manager:

```bash
uv add instructor
poetry add instructor
```

## Provider Compatibility

Use the same code across major LLM providers:

```python
import instructor

# OpenAI
client = instructor.from_provider("openai/gpt-4o")

# Anthropic
client = instructor.from_provider("anthropic/claude-3-5-sonnet")

# Google
client = instructor.from_provider("google/gemini-pro")

# Ollama (local)
client = instructor.from_provider("ollama/llama3.2")

# All use the same API!
user = client.chat.completions.create(
    response_model=User,
    messages=[{"role": "user", "content": "..."}],
)
```

## Advanced Features

### Automatic Retries

Instructor automatically retries failed validations:

```python
from pydantic import BaseModel, field_validator

class User(BaseModel):
    name: str
    age: int

    @field_validator('age')
    def validate_age(cls, v):
        if v < 0:
            raise ValueError('Age must be positive')
        return v

# Instructor automatically retries when validation fails
user = client.chat.completions.create(
    response_model=User,
    messages=[{"role": "user", "content": "..."}],
    max_retries=3,
)
```

### Streaming Support

Stream partial objects as they're generated:

```python
from instructor import Partial

for partial_user in client.chat.completions.create(
    response_model=Partial[User],
    messages=[{"role": "user", "content": "..."}],
    stream=True,
):
    print(partial_user)
    # User(name=None, age=None)
    # User(name="John", age=None)
    # User(name="John", age=25)
```

### Nested Objects

Extract complex, nested data structures:

```python
from typing import List
from pydantic import BaseModel

class Address(BaseModel):
    street: str
    city: str
    country: str

class User(BaseModel):
    name: str
    age: int
    addresses: List[Address]

# Instructor handles nested objects automatically
user = client.chat.completions.create(
    response_model=User,
    messages=[{"role": "user", "content": "..."}],
)
```

## Trusted by the Community

Instructor is a production-ready solution used by 100,000+ developers and companies:

*   **3M+ monthly downloads**
*   **10K+ GitHub stars**
*   **1000+ community contributors**

Companies using Instructor include teams at OpenAI, Google, Microsoft, AWS, and many YC startups.

## Get Started

### Basic Extraction

Extract structured data with ease:

```python
from pydantic import BaseModel
import instructor

client = instructor.from_provider("openai/gpt-4o-mini")

class Product(BaseModel):
    name: str
    price: float
    in_stock: bool

product = client.chat.completions.create(
    response_model=Product,
    messages=[{"role": "user", "content": "iPhone 15 Pro, $999, available now"}],
)

print(product)
# Product(name='iPhone 15 Pro', price=999.0, in_stock=True)
```

### Multiple Languages

Instructor's simple API is available in many languages:

*   [Python](https://python.useinstructor.com) - The original
*   [TypeScript](https://js.useinstructor.com) - Full TypeScript support
*   [Ruby](https://ruby.useinstructor.com) - Ruby implementation
*   [Go](https://go.useinstructor.com) - Go implementation
*   [Elixir](https://hex.pm/packages/instructor) - Elixir implementation
*   [Rust](https://rust.useinstructor.com) - Rust implementation

### Learn More

*   [Documentation](https://python.useinstructor.com) - Comprehensive guides
*   [Examples](https://python.useinstructor.com/examples/) - Copy-paste recipes
*   [Blog](https://python.useinstructor.com/blog/) - Tutorials and best practices
*   [Discord](https://discord.gg/bD9YE9JArw) - Get help from the community

## Why Choose Instructor?

**Over Raw JSON Mode:** Instructor provides automatic validation, retries, streaming, and nested object support without the need for manual schema writing.

**Over LangChain/LlamaIndex:** Instructor is specifically focused on structured extraction, resulting in a lighter, faster, and easier-to-debug solution.

**Over Custom Solutions:** Benefit from a battle-tested library used by thousands of developers, designed to handle a wide range of edge cases.

## Contributing

We welcome contributions!  Check out our [good first issues](https://github.com/instructor-ai/instructor/labels/good%20first%20issue) to get started.

## License

MIT License - see [LICENSE](https://github.com/instructor-ai/instructor/blob/main/LICENSE) for details.

---

<p align="center">
Built by the Instructor community. Special thanks to <a href="https://twitter.com/jxnlco">Jason Liu</a> and all <a href="https://github.com/instructor-ai/instructor/graphs/contributors">contributors</a>.
</p>