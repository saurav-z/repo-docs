# LlamaIndex: Your Data Framework for LLM Applications ðŸ¦™

**Unlock the power of your data with LlamaIndex, a comprehensive framework designed to connect your data to Large Language Models (LLMs), enabling you to build intelligent and context-aware applications.**  ([Original Repository](https://github.com/run-llama/llama_index))

[![PyPI - Downloads](https://img.shields.io/pypi/dm/llama-index)](https://pypi.org/project/llama-index/)
[![Build](https://github.com/run-llama/llama_index/actions/workflows/build_package.yml/badge.svg)](https://github.com/run-llama/llama_index/actions/workflows/build_package.yml)
[![GitHub contributors](https://img.shields.io/github/contributors/jerryjliu/llama_index)](https://github.com/jerryjliu/llama_index/graphs/contributors)
[![Discord](https://img.shields.io/discord/1059199217496772688)](https://discord.gg/dGcwcsnxhU)
[![Twitter](https://img.shields.io/twitter/follow/llama_index)](https://x.com/llama_index)
[![Reddit](https://img.shields.io/reddit/subreddit-subscribers/LlamaIndex?style=plastic&logo=reddit&label=r%2FLlamaIndex&labelColor=white)](https://www.reddit.com/r/LlamaIndex/)
[![Ask AI](https://img.shields.io/badge/Phorm-Ask_AI-%23F2777A.svg?&logo=data:image/svg+xml;base64,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)](https://www.phorm.ai/query?projectId=c5863b56-6703-4a5d-87b6-7e6031bf16b6)

**Key Features:**

*   **Data Connectors:** Seamlessly ingest data from various sources like APIs, PDFs, documents, and SQL databases.
*   **Data Structuring:** Organize your data using efficient structures like indices and graphs, optimized for LLMs.
*   **Advanced Retrieval and Querying:**  Retrieve relevant context and generate knowledge-augmented outputs with an intuitive query interface.
*   **Easy Integrations:** Connect effortlessly with popular frameworks such as LangChain, Flask, and Docker.
*   **Modular Design:**  Customize and extend any module (data connectors, indices, retrievers, query engines) to fit specific needs.

### Table of Contents

*   [Important Links](#important-links)
*   [Ecosystem](#ecosystem)
*   [ðŸš€ Overview](#-overview)
*   [ðŸ’¡ Contributing](#-contributing)
*   [ðŸ“„ Documentation](#-documentation)
*   [ðŸ’» Example Usage](#-example-usage)
*   [ðŸ”§ Dependencies](#-dependencies)
*   [ðŸ“– Citation](#-citation)

### Important Links

*   LlamaIndex.TS [(Typescript/Javascript)](https://github.com/run-llama/LlamaIndexTS)
*   [Documentation](https://docs.llamaindex.ai/en/stable/)
*   [X (formerly Twitter)](https://x.com/llama_index)
*   [LinkedIn](https://www.linkedin.com/company/llamaindex/)
*   [Reddit](https://www.reddit.com/r/LlamaIndex/)
*   [Discord](https://discord.gg/dGcwcsnxhU)

### Ecosystem

*   [LlamaHub](https://llamahub.ai) (community library of data loaders)
*   [LlamaLab](https://github.com/run-llama/llama-lab) (cutting-edge AGI projects using LlamaIndex)

## ðŸš€ Overview

**LlamaIndex empowers you to build powerful LLM applications by providing a comprehensive toolkit for data augmentation.**

### Core Concepts

*   LLMs excel at knowledge generation and reasoning, leveraging vast pre-trained datasets.
*   The key challenge: effectively integrating your *own* private data with LLMs.

### The LlamaIndex Solution

LlamaIndex is your go-to "data framework," offering:

*   **Data Ingestion:** Versatile data connectors for diverse sources (APIs, PDFs, databases, etc.).
*   **Data Structuring:** Organize your data for efficient LLM interaction (indices, graphs).
*   **Querying Capabilities:** A robust interface for retrieving context and generating knowledge-augmented outputs.
*   **Integration Flexibility:** Seamlessly integrate with various application frameworks (LangChain, Flask, Docker, and more).

**Use Cases:**

LlamaIndex supports both beginners and advanced users.

*   **Beginners:** Utilize the high-level API to quickly ingest and query data with just a few lines of code.
*   **Advanced Users:** Customize any module (data connectors, indices, retrievers) for tailored solutions.

## ðŸ’¡ Contributing

We welcome and encourage contributions to both the core LlamaIndex and integrations built upon it. Explore our [Contribution Guide](CONTRIBUTING.md) for detailed information.

*   New integrations should enhance existing LlamaIndex components.
*   LlamaIndex maintainers reserve the right to review and potentially decline integrations.

## ðŸ“„ Documentation

For the most up-to-date information, including tutorials, guides, and references, please visit our comprehensive [documentation](https://docs.llamaindex.ai/en/latest/).

## ðŸ’» Example Usage

```bash
# Install core and select integrations
pip install llama-index-core
pip install llama-index-llms-openai
pip install llama-index-llms-replicate
pip install llama-index-embeddings-huggingface
```

**Example: Building a Vector Store Index with OpenAI**

```python
import os
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader

os.environ["OPENAI_API_KEY"] = "YOUR_OPENAI_API_KEY" # Replace with your key
documents = SimpleDirectoryReader("YOUR_DATA_DIRECTORY").load_data() # Replace with your data dir
index = VectorStoreIndex.from_documents(documents)
```

**Example: Using Non-OpenAI LLMs (Llama 2 on Replicate)**

```python
import os
from llama_index.core import Settings, VectorStoreIndex, SimpleDirectoryReader
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.llms.replicate import Replicate
from transformers import AutoTokenizer

os.environ["REPLICATE_API_TOKEN"] = "YOUR_REPLICATE_API_TOKEN" # Replace with your key

# Configure LLM (Llama 2)
llama2_7b_chat = "meta/llama-2-7b-chat:8e6975e5ed6174911a6ff3d60540dfd4844201974602551e10e9e87ab143d81e"
Settings.llm = Replicate(
    model=llama2_7b_chat,
    temperature=0.01,
    additional_kwargs={"top_p": 1, "max_new_tokens": 300},
)

# Set tokenizer for the LLM
Settings.tokenizer = AutoTokenizer.from_pretrained(
    "NousResearch/Llama-2-7b-chat-hf"
)

# Configure embedding model
Settings.embed_model = HuggingFaceEmbedding(
    model_name="BAAI/bge-small-en-v1.5"
)

documents = SimpleDirectoryReader("YOUR_DATA_DIRECTORY").load_data() # Replace with your data dir
index = VectorStoreIndex.from_documents(documents)
```

**Querying the Index:**

```python
query_engine = index.as_query_engine()
query_engine.query("YOUR_QUESTION") # Replace with your question
```

**Persistence (Save/Load to Disk):**

```python
# To persist to disk
index.storage_context.persist()

# To load from disk
from llama_index.core import StorageContext, load_index_from_storage

storage_context = StorageContext.from_defaults(persist_dir="./storage")
index = load_index_from_storage(storage_context)
```

## ðŸ”§ Dependencies

LlamaIndex uses `poetry` for Python package management. You can find the dependencies in the `pyproject.toml` file within each package folder.

```bash
cd <desired-package-folder>
pip install poetry
poetry install --with dev
```

## ðŸ“– Citation

If you use LlamaIndex in your research, please cite it as:

```
@software{Liu_LlamaIndex_2022,
author = {Liu, Jerry},
doi = {10.5281/zenodo.1234},
month = {11},
title = {{LlamaIndex}},
url = {https://github.com/jerryjliu/llama_index},
year = {2022}
}
```