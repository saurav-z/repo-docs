<h1 align="center">
  <a href="https://github.com/RoboTwin-Platform/RoboTwin"><b>RoboTwin: The Bimanual Robotic Manipulation Platform</b></a>
</h1>

<h2 align="center">
  Empowering Bimanual Robotic Manipulation with Advanced Benchmarking and Domain Randomization.
  <br>
  Latest Version: RoboTwin 2.0 
  <br>
  ü§≤ <a href="https://robotwin-platform.github.io/">Webpage</a> | <a href="https://robotwin-platform.github.io/doc/">Documentation</a> | <a href="https://arxiv.org/abs/2506.18088">Paper</a> | <a href="https://robotwin-platform.github.io/doc/community/index.html">Community</a>
</h2>

[![RoboTwin 2.0 Demo](https://private-user-images.githubusercontent.com/88101805/463126988-e3ba1575-4411-4a36-ad65-f0b2f49890c3.mp4)](https://github.com/RoboTwin-Platform/RoboTwin)

## Key Features

*   **Scalable Data Generation:** RoboTwin 2.0 offers a robust data generation pipeline.
*   **Strong Domain Randomization:**  Enhance the model's ability to generalize
*   **Comprehensive Benchmarking:** Evaluate your bimanual robotic manipulation algorithms.
*   **Multiple Versions:** Access to the latest RoboTwin 2.0 and previous versions.
*   **Open Source:** MIT Licensed, promoting open research and community contribution.

## Versions & Related Projects

*   **RoboTwin 2.0 (Latest):**  A Scalable Data Generator and Benchmark with Strong Domain Randomization for Robust Bimanual Robotic Manipulation - *Under Review 2025*
    *   [Webpage](https://robotwin-platform.github.io/) | [Document](https://robotwin-platform.github.io/doc) | [PDF](https://arxiv.org/pdf/2506.18088) | [arXiv](https://arxiv.org/abs/2506.18088)
    *   [Talk (in Chinese)](https://www.bilibili.com/video/BV18p3izYE63/?spm_id_from=333.337.search-card.all.click) | [Êú∫Âô®‰πãÂøÉ](https://mp.weixin.qq.com/s/SwORezmol2Qd9YdrGYchEA)
*   **RoboTwin Dual-Arm Collaboration Challenge@CVPR'25 MEIS Workshop**
    *   Official Technical Report: [PDF](https://arxiv.org/pdf/2506.23351) | [arXiv](https://arxiv.org/abs/2506.23351) | [ÈáèÂ≠ê‰Ωç](https://mp.weixin.qq.com/s/qxqs9vvvHsAJ-0hoYANYzQ)
*   **RoboTwin 1.0:** Dual-Arm Robot Benchmark with Generative Digital Twins.
    *   Accepted to <i style="color: red; display: inline;"><b>CVPR 2025 (Highlight)</b></i>: [PDF](https://arxiv.org/pdf/2504.13059) | [arXiv](https://arxiv.org/abs/2504.13059)
*   **Early Version:** Dual-Arm Robot Benchmark with Generative Digital Twins (early version)
    *   Accepted to <i style="color: red; display: inline;"><b>ECCV Workshop 2024 (Best Paper Award)</b></i>: [PDF](https://arxiv.org/pdf/2409.02920) | [arXiv](https://arxiv.org/abs/2409.02920)

## üìö Overview

| Branch Name                     | Link                                                                                             |
| ------------------------------- | ------------------------------------------------------------------------------------------------ |
| 2.0 Version Branch              | [main](https://github.com/RoboTwin-Platform/RoboTwin/tree/main) (latest)                          |
| 1.0 Version Branch              | [1.0 Version](https://github.com/RoboTwin-Platform/RoboTwin/tree/RoboTwin-1.0)                    |
| 1.0 Version Code Generation Branch | [1.0 Version GPT](https://github.com/RoboTwin-Platform/RoboTwin/tree/gpt)                     |
| Early Version Branch            | [Early Version](https://github.com/RoboTwin-Platform/RoboTwin/tree/early_version)                   |
| Á¨¨ÂçÅ‰πùÂ±ä‚ÄúÊåëÊàòÊùØ‚Äù‰∫∫Â∑•Êô∫ËÉΩ‰∏ìÈ°πËµõÂàÜÊîØ | [Challenge-Cup-2025](https://github.com/RoboTwin-Platform/RoboTwin/tree/Challenge-Cup-2025) |
| CVPR 2025 Challenge Round 1 Branch | [CVPR-Challenge-2025-Round1](https://github.com/RoboTwin-Platform/RoboTwin/tree/CVPR-Challenge-2025-Round1) |
| CVPR 2025 Challenge Round 2 Branch | [CVPR-Challenge-2025-Round2](https://github.com/RoboTwin-Platform/RoboTwin/tree/CVPR-Challenge-2025-Round2) |

## üê£ Recent Updates

*   **2025/07/23:** RoboTwin 2.0 received Outstanding Poster at ChinaSI 2025 (Ranking 1st).
*   **2025/07/19:** Fixed DP3 evaluation code error.
*   **2025/07/09:** Updated endpose control mode.  See [[RoboTwin Doc - Usage - Control Robot](https://robotwin-platform.github.io/doc/usage/control-robot.html)]
*   **2025/07/08:**  Released [Challenge-Cup-2025](https://github.com/RoboTwin-Platform/RoboTwin/tree/Challenge-Cup-2025) branch.
*   **2025/07/02:** Fixed Piper Wrist Bug [[issue](https://github.com/RoboTwin-Platform/RoboTwin/issues/104)].
*   **2025/07/01:** Released Technical Report of RoboTwin Dual-Arm Collaboration Challenge @ CVPR 2025 MEIS Workshop [[arXiv](https://arxiv.org/abs/2506.23351)] !
*   **2025/06/21:** Released RoboTwin 2.0 [[Webpage](https://robotwin-platform.github.io/)] !
*   **2025/04/11:** RoboTwin selected as <i>CVPR Highlight paper</i>!
*   **2025/02/27:** RoboTwin is accepted to <i>CVPR 2025</i> !
*   **2024/09/30:** RoboTwin (Early Version) received <i>the Best Paper Award  at the ECCV Workshop</i>!
*   **2024/09/20:** Officially released RoboTwin.

## üõ†Ô∏è Installation

Detailed installation instructions are available in the [RoboTwin 2.0 Document (Usage - Install & Download)](https://robotwin-platform.github.io/doc/usage/robotwin-install.html). Installation takes approximately 20 minutes.

## ü§∑‚Äç‚ôÇÔ∏è Tasks Information

For detailed information about the available tasks, please refer to the [RoboTwin 2.0 Tasks Doc](https://robotwin-platform.github.io/doc/tasks/index.html).

<p align="center">
  <img src="./assets/files/50_tasks.gif" width="100%">
</p>

## üßëüèª‚Äçüíª Usage

> Detailed usage instructions can be found in the [RoboTwin 2.0 Document (Usage)](https://robotwin-platform.github.io/doc/usage/index.html).

### Data Collection

RoboTwin provides over 100,000 pre-collected trajectories in the [RoboTwin Dataset](https://huggingface.co/datasets/TianxingChen/RoboTwin2.0/tree/main/dataset). However, it is recommended to perform your own data collection.

<img src="./assets/files/domain_randomization.png" alt="description" style="display: block; margin: auto; width: 100%;">

### 1. Task Running and Data Collection

Collect data using the following command, which searches for a random seed and replays it to collect data:

```bash
bash collect_data.sh ${task_name} ${task_config} ${gpu_id}
# Example: bash collect_data.sh beat_block_hammer demo_randomized 0
```

### 2. Task Configuration

Refer to the [RoboTwin 2.0 Tasks Configurations Doc](https://robotwin-platform.github.io/doc/usage/configurations.html) for task configuration details.

## üö¥‚Äç‚ôÇÔ∏è Policy Baselines

### Policies Support

*   [DP](https://robotwin-platform.github.io/doc/usage/DP.html)
*   [ACT](https://robotwin-platform.github.io/doc/usage/ACT.html)
*   [DP3](https://robotwin-platform.github.io/doc/usage/DP3.html)
*   [RDT](https://robotwin-platform.github.io/doc/usage/RDT.html)
*   [PI0](https://robotwin-platform.github.io/doc/usage/Pi0.html)
*   [TinyVLA](https://robotwin-platform.github.io/doc/usage/TinyVLA.html)
*   [DexVLA](https://robotwin-platform.github.io/doc/usage/DexVLA.html) (Contributed by Media Group)
*   [LLaVA-VLA](https://robotwin-platform.github.io/doc/usage/LLaVA-VLA.html) (Contributed by IRPN Lab, HKUST(GZ))

Deploy Your Policy: [guide](https://robotwin-platform.github.io/doc/usage/deploy-your-policy.html)

‚è∞ TODO: G3Flow, HybridVLA, DexVLA, OpenVLA-OFT, SmolVLA, AVR, UniVLA

## üèÑ‚Äç‚ôÇÔ∏è Experiment & LeaderBoard

> Explore the RoboTwin Platform for:
> 1.  Single-task fine-tuning
> 2.  Visual robustness
> 3.  Language diversity robustness (language condition)
> 4.  Multi-task capability
> 5.  Cross-embodiment performance

Coming Soon.

## üëç Citations

If you find our work useful, please cite the following:

**RoboTwin 2.0:** A Scalable Data Generator and Benchmark with Strong Domain Randomization for Robust Bimanual Robotic Manipulation

```
@article{chen2025robotwin,
  title={RoboTwin 2.0: A Scalable Data Generator and Benchmark with Strong Domain Randomization for Robust Bimanual Robotic Manipulation},
  author={Chen, Tianxing and Chen, Zanxin and Chen, Baijun and Cai, Zijian and Liu, Yibin and Liang, Qiwei and Li, Zixuan and Lin, Xianliang and Ge, Yiheng and Gu, Zhenyu and others},
  journal={arXiv preprint arXiv:2506.18088},
  year={2025}
}
```

**RoboTwin:** Dual-Arm Robot Benchmark with Generative Digital Twins, accepted to <i style="color: red; display: inline;"><b>CVPR 2025 (Highlight)</b></i>

```
@InProceedings{Mu_2025_CVPR,
    author    = {Mu, Yao and Chen, Tianxing and Chen, Zanxin and Peng, Shijia and Lan, Zhiqian and Gao, Zeyu and Liang, Zhixuan and Yu, Qiaojun and Zou, Yude and Xu, Mingkun and Lin, Lunkai and Xie, Zhiqiang and Ding, Mingyu and Luo, Ping},
    title     = {RoboTwin: Dual-Arm Robot Benchmark with Generative Digital Twins},
    booktitle = {Proceedings of the Computer Vision and Pattern Recognition Conference (CVPR)},
    month     = {June},
    year      = {2025},
    pages     = {27649-27660}
}
```

**Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop**

```
@article{chen2025benchmarking,
  title={Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop},
  author={Chen, Tianxing and Wang, Kaixuan and Yang, Zhaohui and Zhang, Yuhao and Chen, Zanxin and Chen, Baijun and Dong, Wanxi and Liu, Ziyuan and Chen, Dong and Yang, Tianshuo and others},
  journal={arXiv preprint arXiv:2506.23351},
  year={2025}
}
```

**RoboTwin:** Dual-Arm Robot Benchmark with Generative Digital Twins (early version), accepted to <i style="color: red; display: inline;"><b>ECCV Workshop 2024 (Best Paper Award)</b></i>

```
@article{mu2024robotwin,
  title={RoboTwin: Dual-Arm Robot Benchmark with Generative Digital Twins (early version)},
  author={Mu, Yao and Chen, Tianxing and Peng, Shijia and Chen, Zanxin and Gao, Zeyu and Zou, Yude and Lin, Lunkai and Xie, Zhiqiang and Luo, Ping},
  journal={arXiv preprint arXiv:2409.02920},
  year={2024}
}
```

## üò∫ Acknowledgement

**Software Support**: D-Robotics, **Hardware Support**: AgileX Robotics, **AIGC Support**: Deemos

Code Style: `find . -name "*.py" -exec sh -c 'echo "Processing: {}"; yapf -i --style='"'"'{based_on_style: pep8, column_limit: 120}'"'"' {}' \;`

For any questions or suggestions, please contact [Tianxing Chen](https://tianxingchen.github.io).

## üè∑Ô∏è License

This repository is released under the MIT license. See [LICENSE](./LICENSE) for more details.