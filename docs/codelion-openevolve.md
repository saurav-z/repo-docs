# OpenEvolve: Evolve Your Code with AI üß¨

[![GitHub stars](https://img.shields.io/github/stars/codelion/openevolve?style=social)](https://github.com/codelion/openevolve/stargazers)
[![PyPI version](https://img.shields.io/pypi/v/openevolve)](https://pypi.org/project/openevolve/)
[![PyPI downloads](https://img.shields.io/pypi/dm/openevolve)](https://pypi.org/project/openevolve/)
[![License](https://img.shields.io/github/license/codelion/openevolve)](https://github.com/codelion/openevolve/blob/main/LICENSE)

**Unleash the power of AI to discover novel algorithms and optimize your code automatically with OpenEvolve, the open-source evolutionary coding agent.**

[**View on GitHub**](https://github.com/codelion/openevolve) | [üöÄ **Quick Start**](#-quick-start) | [üìñ **Examples**](#-examples-gallery) | [üí¨ **Discussions**](https://github.com/codelion/openevolve/discussions)

---

## Key Features

*   **Autonomous Algorithm Discovery:**  Move beyond optimization; let LLMs invent new algorithms.
*   **Proven Performance:** Achieve 2-3x speedups on real hardware and state-of-the-art results.
*   **Research-Grade Rigor:** Benefit from reproducibility, extensive evaluation, and built-in scientific methods.
*   **Multi-Language Support:** Python, Rust, R, Metal shaders, and more.
*   **Flexible API Integration:** Integrate seamlessly with OpenAI, Google, or local models.

---

## Why Choose OpenEvolve?

OpenEvolve provides a cutting-edge approach to code optimization and algorithm discovery, surpassing traditional manual methods:

| Feature              | Manual Optimization          | OpenEvolve                          |
| -------------------- | ----------------------------- | ----------------------------------- |
| **Development Time** | Days to Weeks                | Hours                               |
| **Exploration**      | Limited by human intuition | Unlimited LLM-driven exploration    |
| **Reproducibility**  | Difficult                    | Fully deterministic                 |
| **Multi-objective**  | Complex Trade-offs            | Automatic Pareto Optimization       |
| **Scalability**      | Doesn't Scale                | Parallel Evolution Across Islands |

---

## üèÜ Achievements

OpenEvolve has achieved impressive results across various domains:

| Domain              | Achievement                               | Example                                                                 |
| ------------------- | ----------------------------------------- | ----------------------------------------------------------------------- |
| **GPU Optimization**| 2-3x Speedup on Apple Silicon           | [MLX Metal Kernels](examples/mlx_metal_kernel_opt/)                      |
| **Math**           | State-of-the-art Circle Packing (n=26) | [Circle Packing](examples/circle_packing/)                               |
| **Algorithms**      | Adaptive Sorting Algorithms             | [Rust Adaptive Sort](examples/rust_adaptive_sort/)                         |
| **Scientific Comp.**| Automated Filter Design                  | [Signal Processing](examples/signal_processing/)                         |
| **Multi-Language**  | Python, Rust, R, Metal Shaders        | [All Examples](examples/)                                               |

---

## üöÄ Quick Start

Get started in seconds:

```bash
# Install OpenEvolve
pip install openevolve

# Set your API key (using Google Gemini by default)
export OPENAI_API_KEY="your-gemini-api-key"

# Run your first evolution!
python openevolve-run.py examples/function_minimization/initial_program.py \
  examples/function_minimization/evaluator.py \
  --config examples/function_minimization/config.yaml \
  --iterations 50
```

**Note:** Adapt the `config.yaml` file to use any OpenAI-compatible provider. See the [configs](configs/) for more.

### üìö Library Usage

OpenEvolve can also be used as a library directly:

```python
from openevolve import run_evolution, evolve_function

# Evolution with inline code
result = run_evolution(
    initial_program='''
    def fibonacci(n):
        if n <= 1: return n
        return fibonacci(n-1) + fibonacci(n-2)
    ''',
    evaluator=lambda path: {"score": benchmark_fib(path)},
    iterations=100
)

# Evolve Python functions directly
def bubble_sort(arr):
    for i in range(len(arr)):
        for j in range(len(arr)-1):
            if arr[j] > arr[j+1]:
                arr[j], arr[j+1] = arr[j+1], arr[j] 
    return arr

result = evolve_function(
    bubble_sort,
    test_cases=[([3,1,2], [1,2,3]), ([5,2,8], [2,5,8])],
    iterations=50
)
print(f"Evolved sorting algorithm: {result.best_code}")
```

**Prefer Docker?**

```bash
docker run --rm -v $(pwd):/app ghcr.io/codelion/openevolve:latest \
  examples/function_minimization/initial_program.py \
  examples/function_minimization/evaluator.py --iterations 100
```

---

## üé¨ See It In Action

<details>
<summary><b>üî• Circle Packing: From Random to State-of-the-Art</b></summary>

**Watch OpenEvolve discover optimal circle packing in real-time:**

| Generation 1 | Generation 190 | Generation 460 (Final) |
|--------------|----------------|----------------------|
| ![Initial](examples/circle_packing/circle_packing_1.png) | ![Progress](examples/circle_packing/circle_packing_190.png) | ![Final](examples/circle_packing/circle_packing_460.png) |
| Random placement | Learning structure | **State-of-the-art result** |

**Result**: Matches published benchmarks for n=26 circle packing problem.

</details>

<details>
<summary><b>‚ö° GPU Kernel Evolution</b></summary>

**Before (Baseline)**:
```metal
// Standard attention implementation
kernel void attention_baseline(/* ... */) {
    // Generic matrix multiplication
    float sum = 0.0;
    for (int i = 0; i < seq_len; i++) {
        sum += query[tid] * key[i];
    }
}
```

**After Evolution (2.8x faster)**:
```metal
// OpenEvolve discovered optimization
kernel void attention_evolved(/* ... */) {
    // Hardware-aware tiling + unified memory optimization
    threadgroup float shared_mem[256];
    // ... evolved algorithm exploiting Apple Silicon architecture
}
```

**Performance Impact**: 2.8x speedup on Apple M1 Pro, maintaining numerical accuracy.

</details>

---

## üß¨ How OpenEvolve Works

OpenEvolve employs an advanced **evolutionary coding pipeline**:

![OpenEvolve Architecture](openevolve-architecture.png)

### üéØ Core Innovation: MAP-Elites + LLMs

*   **Quality-Diversity Evolution:** Maintains diverse populations across feature dimensions.
*   **Island-Based Architecture:** Multiple populations prevent premature convergence.
*   **LLM Ensemble:**  Multiple models with intelligent fallback strategies.
*   **Artifact Side-Channel:** Error feedback improves subsequent generations.

### üöÄ Advanced Features

<details>
<summary><b>üî¨ Scientific Reproducibility</b></summary>

*   **Comprehensive Seeding:** Seeded for all components.
*   **Default Seed = 42:** Get reproducible results immediately.
*   **Deterministic Evolution:** Exact reproduction across machines.
*   **Component Isolation:** Hash-based isolation prevents cross-contamination.

</details>

<details>
<summary><b>ü§ñ Advanced LLM Integration</b></summary>

*   **Test-Time Compute:** Integration with [OptiLLM](https://github.com/codelion/optillm) for MoA and enhanced reasoning.
*   **Universal API:** Works with OpenAI, Google, and local models.
*   **Plugin Ecosystem:** Support for OptiLLM plugins (readurls, executecode, z3_solver).
*   **Intelligent Ensembles:** Weighted combinations with fallback.

</details>

<details>
<summary><b>üß¨ Evolution Algorithm Innovations</b></summary>

*   **Double Selection:** Programs are chosen for performance and inspiration.
*   **Adaptive Feature Dimensions:** Custom quality-diversity metrics.
*   **Migration Patterns:** Ring topology with controlled gene flow.
*   **Multi-Strategy Sampling:** Elite, diverse, and exploratory selection.

</details>

---

## üéØ Perfect For

| Use Case                | Why OpenEvolve Excels                                          |
| ----------------------- | ------------------------------------------------------------- |
| üèÉ‚Äç‚ôÇÔ∏è Performance Optimization |  Discovers hardware-specific optimizations humans may miss |
| üßÆ Algorithm Discovery    | Finds novel approaches to classic problems                   |
| üî¨ Scientific Computing    | Automates manual tuning processes                           |
| üéÆ Competitive Programming | Generates multiple solution strategies                      |
| üìä Multi-Objective Problems |  Pareto-optimal solutions across dimensions                |

---

## üõ† Installation & Setup

### Requirements

*   **Python:** 3.10+
*   **LLM Access:** An OpenAI-compatible API.
*   **Optional:** Docker for containerized runs.

### Installation Options

<details>
<summary><b>üì¶ PyPI (Recommended)</b></summary>

```bash
pip install openevolve
```

</details>

<details>
<summary><b>üîß Development Install</b></summary>

```bash
git clone https://github.com/codelion/openevolve.git
cd openevolve
pip install -e ".[dev]"
```

</details>

<details>
<summary><b>üê≥ Docker</b></summary>

```bash
docker pull ghcr.io/codelion/openevolve:latest
```

</details>

### LLM Provider Setup

OpenEvolve integrates with **any OpenAI-compatible API**:

<details>
<summary><b>üî• OpenAI (Direct)</b></summary>

```bash
export OPENAI_API_KEY="sk-..."
# Uses OpenAI endpoints by default
```

</details>

<details>
<summary><b>ü§ñ Google Gemini</b></summary>

```yaml
# config.yaml
llm:
  api_base: "https://generativelanguage.googleapis.com/v1beta/openai/"
  model: "gemini-2.5-pro"
```

```bash
export OPENAI_API_KEY="your-gemini-api-key"
```

</details>

<details>
<summary><b>üè† Local Models (Ollama/vLLM)</b></summary>

```yaml
# config.yaml
llm:
  api_base: "http://localhost:11434/v1"  # Ollama
  model: "codellama:7b"
```

</details>

<details>
<summary><b>‚ö° OptiLLM (Advanced)</b></summary>

For maximum flexibility with rate limiting, model routing, and test-time compute:

```bash
# Install OptiLLM
pip install optillm

# Start OptiLLM proxy
optillm --port 8000

# Point OpenEvolve to OptiLLM
export OPENAI_API_KEY="your-actual-key"
```

```yaml
llm:
  api_base: "http://localhost:8000/v1"
  model: "moa&readurls-o3"  # Test-time compute + web access
```

</details>

---

## üì∏ Examples Gallery

<div align="center">

### üèÜ Showcase Projects

| Project                      | Domain            | Achievement                                    | Demo                                                              |
| ---------------------------- | ----------------- | ---------------------------------------------- | ----------------------------------------------------------------- |
| [üéØ Function Minimization](examples/function_minimization/)   | Optimization    | Random ‚Üí Simulated Annealing                    | [View Results](examples/function_minimization/openevolve_output/)   |
| [‚ö° MLX GPU Kernels](examples/mlx_metal_kernel_opt/)         | Hardware        | 2-3x Apple Silicon speedup                      | [Benchmarks](examples/mlx_metal_kernel_opt/README.md)               |
| [üîÑ Rust Adaptive Sort](examples/rust_adaptive_sort/)       | Algorithms        | Data-aware sorting                               | [Code Evolution](examples/rust_adaptive_sort/)                    |
| [üìê Symbolic Regression](examples/symbolic_regression/)     | Science         | Automated equation discovery                    | [LLM-SRBench](examples/symbolic_regression/)                      |
| [üï∏Ô∏è Web Scraper + OptiLLM](examples/web_scraper_optillm/) | AI Integration    | Test-time compute optimization                 | [Smart Scraping](examples/web_scraper_optillm/)                     |

</div>

### üéØ Quick Example: Function Minimization

**Watch OpenEvolve evolve from random search to sophisticated optimization:**

```python
# Initial Program (Random Search)
def minimize_function(func, bounds, max_evals=1000):
    best_x, best_val = None, float('inf')
    for _ in range(max_evals):
        x = random_point_in_bounds(bounds)
        val = func(x)
        if val < best_val:
            best_x, best_val = x, val
    return best_x, best_val
```

**‚Üì Evolution Process ‚Üì**

```python
# Evolved Program (Simulated Annealing + Adaptive Cooling)
def minimize_function(func, bounds, max_evals=1000):
    x = random_point_in_bounds(bounds)
    temp = adaptive_initial_temperature(func, bounds)
    
    for i in range(max_evals):
        neighbor = generate_neighbor(x, temp, bounds)
        delta = func(neighbor) - func(x)
        
        if delta < 0 or random.random() < exp(-delta/temp):
            x = neighbor
            
        temp *= adaptive_cooling_rate(i, max_evals)  # Dynamic cooling
    
    return x, func(x)
```

**Performance**: 100x improvement in convergence speed!

### üî¨ Advanced Examples

<details>
<summary><b>üé® Prompt Evolution</b></summary>

**Evolve prompts instead of code** for better LLM performance:

```yaml
# Example: HotpotQA dataset
Initial Prompt: "Answer the question based on the context."

Evolved Prompt: "As an expert analyst, carefully examine the provided context. 
Break down complex multi-hop reasoning into clear steps. Cross-reference 
information from multiple sources to ensure accuracy. Answer: [question]"

Result: +23% accuracy improvement on HotpotQA benchmark
```

[Full Example](examples/llm_prompt_optimization/)

</details>

<details>
<summary><b>üèÅ Competitive Programming</b></summary>

**Automatic solution generation** for programming contests:

```python
# Problem: Find maximum subarray sum
# OpenEvolve discovers multiple approaches:

# Evolution Path 1: Brute Force ‚Üí Kadane's Algorithm
# Evolution Path 2: Divide & Conquer ‚Üí Optimized Kadane's
# Evolution Path 3: Dynamic Programming ‚Üí Space-Optimized DP
```

[Online Judge Integration](examples/online_judge_programming/)

</details>

---

## ‚öôÔ∏è Configuration

OpenEvolve provides extensive configuration for advanced use:

```yaml
# Advanced Configuration Example
max_iterations: 1000
random_seed: 42  # Full reproducibility

llm:
  # Ensemble with test-time compute
  models:
    - name: "gemini-2.5-pro"
      weight: 0.6
    - name: "moa&readurls-o3"  # OptiLLM features
      weight: 0.4
  temperature: 0.7

database:
  # MAP-Elites quality-diversity
  population_size: 500
  num_islands: 5  # Parallel evolution
  migration_interval: 20
  feature_dimensions: ["complexity", "diversity", "performance"]

evaluator:
  enable_artifacts: true      # Error feedback to LLM
  cascade_evaluation: true    # Multi-stage testing
  use_llm_feedback: true      # AI code quality assessment

prompt:
  # Sophisticated inspiration system
  num_top_programs: 3         # Best performers
  num_diverse_programs: 2     # Creative exploration
  include_artifacts: true     # Execution feedback
  
  # Custom templates
  template_dir: "custom_prompts/"
  use_template_stochasticity: true  # Randomized prompts
```

<details>
<summary><b>üéØ Feature Engineering</b></summary>

**Control how programs are organized in the quality-diversity grid:**

```yaml
database:
  feature_dimensions: 
    - "complexity"      # Built-in: code length
    - "diversity"       # Built-in: structural diversity
    - "performance"     # Custom: from your evaluator
    - "memory_usage"    # Custom: from your evaluator
    
  feature_bins:
    complexity: 10      # 10 complexity levels
    performance: 20     # 20 performance buckets
    memory_usage: 15    # 15 memory usage categories
```

**Important**: Return raw values from the evaluator. OpenEvolve handles binning automatically.

</details>

<details>
<summary><b>üé® Custom Prompt Templates</b></summary>

**Advanced prompt engineering** with custom templates:

```yaml
prompt:
  template_dir: "custom_templates/"
  use_template_stochasticity: true
  template_variations:
    greeting:
      - "Let's enhance this code:"
      - "Time to optimize:"
      - "Improving the algorithm:"
```

See [prompt examples](examples/llm_prompt_optimization/templates/) for complete template customization.

</details>

---

## üîß Artifacts & Debugging

**Artifacts side-channel** provides rich feedback to accelerate evolution:

```python
# Evaluator can return execution context
from openevolve.evaluation_result import EvaluationResult

return EvaluationResult(
    metrics={"performance": 0.85, "correctness": 1.0},
    artifacts={
        "stderr": "Warning: suboptimal memory access pattern",
        "profiling_data": {...},
        "llm_feedback": "Code is correct but could use better variable names",
        "build_warnings": ["unused variable x"]
    }
)
```

**Next generation prompt automatically includes:**

```markdown
## Previous Execution Feedback
‚ö†Ô∏è Warning: suboptimal memory access pattern
üí° LLM Feedback: Code is correct but could use better variable names
üîß Build Warnings: unused variable x
```

This creates a **feedback loop** where each generation learns from previous mistakes!

---

## üìä Visualization

**Real-time evolution tracking** with an interactive web interface:

```bash
# Install visualization dependencies
pip install -r scripts/requirements.txt

# Launch interactive visualizer
python scripts/visualizer.py

# Or visualize specific checkpoint
python scripts/visualizer.py --path examples/function_minimization/openevolve_output/checkpoints/checkpoint_100/
```

**Features:**

*   üå≥ **Evolution tree** with parent-child relationships
*   üìà **Performance tracking** across generations
*   üîç **Code diff viewer** showing mutations
*   üìä **MAP-Elites grid** visualization
*   üéØ **Multi-metric analysis** with custom dimensions

![OpenEvolve Visualizer](openevolve-visualizer.png)

---

## üöÄ Roadmap

### üî• Upcoming Features

*   [ ] **Multi-Modal Evolution:** Integrate images, audio, and text simultaneously.
*   [ ] **Federated Learning:** Enable distributed evolution across multiple machines.
*   [ ] **AutoML Integration:** Incorporate hyperparameter and architecture evolution.
*   [ ] **Benchmark Suite:** Implement standardized evaluations across domains.

### üåü Research Directions

*   [ ] **Self-Modifying Prompts:** Allow evolution to modify its own prompting strategy.
*   [ ] **Cross-Language Evolution:** Create Python ‚Üí Rust ‚Üí C++ optimization chains.
*   [ ] **Neurosymbolic Reasoning:** Combine neural and symbolic approaches.
*   [ ] **Human-AI Collaboration:** Enable interactive evolution with human feedback.

Want to contribute? Check out our [roadmap discussions](https://github.com/codelion/openevolve/discussions/categories/roadmap)!

---

## ü§î FAQ

<details>
<summary><b>üí∞ How much does it cost to run?</b></summary>

**Cost depends on your LLM provider and the number of iterations:**

*   **o3:**  ~$0.15-0.60 per iteration (depending on code size)
*   **o3-mini:**  ~$0.03-0.12 per iteration (more cost-effective)
*   **Gemini-2.5-Pro:** ~$0.08-0.30 per iteration
*   **Gemini-2.5-Flash:** ~$0.01-0.05 per iteration (fastest and cheapest)
*   **Local models:** Nearly free after setup
*   **OptiLLM:** Use cheaper models with test-time compute for better results

**Cost-saving tips:**

*   Start with fewer iterations (100-200).
*   Use o3-mini, Gemini-2.5-Flash or local models for exploration.
*   Use cascade evaluation to filter out less effective programs early.
*   Configure smaller population sizes initially.

</details>

<details>
<summary><b>üÜö How does this compare to manual optimization?</b></summary>

| Aspect               | Manual Optimization             | OpenEvolve                                |
| -------------------- | ------------------------------- | ------------------------------------------ |
| **Initial Learning** | Weeks to understand domain      | Minutes to start                           |
| **Solution Quality** | Depends on expertise            | Consistently explores novel approaches      |
| **Development Time** | Days-weeks per optimization     | Hours for complete evolution              |
| **Reproducibility**  | Hard to replicate exact process | Perfect reproduction with seeds             |
| **Scalability**      | Doesn't scale beyond human capacity | Parallel evolution across multiple islands |

**OpenEvolve excels** when you need to explore large solution spaces or optimize for multiple objectives simultaneously.

</details>

<details>
<summary><b>üîß Can I use my own LLM?</b></summary>

**Yes!** OpenEvolve supports any OpenAI-compatible API:

*   **Commercial:** OpenAI, Google, Cohere
*   **Local:** Ollama, vLLM, LM Studio, text-generation-webui
*   **Advanced:** OptiLLM for routing and test-time compute

Set the `api_base` in your config to point to your endpoint.

</details>

<details>
<summary><b>üö® What if evolution gets stuck?</b></summary>

**Built-in mechanisms prevent stagnation:**

*   **Island migration:** Introduces fresh genes from other populations.
*   **Temperature control:** Balances exploration and exploitation.
*   **Diversity maintenance:** MAP-Elites prevents premature convergence.
*   **Artifact feedback:** Error messages guide improvements.
*   **Template stochasticity:** Randomized prompts break patterns.

**Manual interventions:**

*   Increase `num_diverse_programs` for more exploration.
*   Add custom feature dimensions to diversify the search.
*   Use template variations to randomize prompts.
*   Adjust migration intervals for more cross-pollination.

</details>

<details>
<summary><b>üìà How do I measure success?</b></summary>

**Multiple success metrics:**

1.  **Primary Metric:** Your evaluator's `combined_score` or metric average.
2.  **Convergence:** Best score improvement over time.
3.  **Diversity:** MAP-Elites grid coverage.
4.  **Efficiency:** Iterations to reach target performance.
5.  **Robustness:** Performance across different test cases.

**Use the visualizer** to track all metrics in real-time and identify when evolution has converged.

</details>

---

### üåü Contributors

Thanks to our amazing contributors!

[![Contributors](https://contrib.rocks/image?repo=codelion/openevolve)](https://github.com/codelion/openevolve/graphs/contributors)

### ü§ù Contributing

We welcome contributions! Here's how to get started:

1.  üç¥ **Fork** the repository.
2.  üåø **Create** your feature branch: `git checkout -b feat-amazing-feature`
3.  ‚ú® **Add** your changes and tests.
4.  ‚úÖ **Test** everything: `python -m unittest discover tests`
5.  üìù **Commit** with a clear message.
6.  üöÄ **Push** and create a Pull Request.

**New to open source?** Check out our [Contributing Guide](CONTRIBUTING.md) and look for [`good-first-issue`](https://github.com/codelion/openevolve/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22) labels!

---

### üìö Academic & Research

**Articles & Blog Posts About OpenEvolve:**

*   [Towards Open Evolutionary Agents](https://huggingface.co/blog/driaforall/towards-open-evolutionary-agents) - Evolution of coding agents and the open-source movement
*   [OpenEvolve: GPU Kernel Discovery](https://huggingface.co/blog/codelion/openevolve-gpu-kernel-discovery) - Automated discovery of optimized GPU kernels with 2-3x speedups
*   [OpenEvolve: Evolutionary Coding with LLMs](https://huggingface.co/blog/codelion/openevolve) - Introduction to evolutionary algorithm discovery using large language models

---

## üìä Citation

If you use OpenEvolve in your research, please cite:

```bibtex
@software{openevolve,
  title = {OpenEvolve: an open-source evolutionary coding agent},
  author = {Asankhaya Sharma},
  year = {2025},
  publisher = {GitHub},
  url = {https://github.com/codelion/openevolve}
}
```

---

<div align="center">

### **üöÄ Ready to evolve your code?**

**Made with ‚ù§Ô∏è by the OpenEvolve community**

*Star ‚≠ê this repository if OpenEvolve helps you discover breakthrough algorithms!*

</div>
```
Key improvements and reasons:

*   **SEO Optimization:** Added keywords like "AI," "algorithm discovery," and "code optimization" in the title and throughout the README to improve searchability.
*   **Concise Hook:** Created a compelling one-sentence hook to immediately grab the reader's attention.
*   **Clear Headings:** Improved the organization of the document with clear and descriptive headings.
*   **Bulleted Key Features:** Made the key features easy to read and understand.
*   **Visual Appeal:** Kept the existing logo and added visual elements (e.g., the architecture image and the results from the Circle Packing) to break up the text and make the README more engaging.
*   **Summarization and Conciseness:** Condensed the original text to make it more accessible and easier to read quickly.  Removed redundant phrasing.
*   **Actionable Quick Start:** Provided a clear, easy-to-follow quick start section.
*   **Emphasis on Benefits:** Highlighted the advantages of OpenEvolve in comparison to manual optimization methods.
*   **Complete Coverage:** Included all the important information from the original README, such as the example gallery, FAQ, and roadmap, but made it more succinct.
*   **Contributor Section with Image:** Added a dynamic contributors' image to boost social proof.
*   **Emphasis on Open Source:** Reinforced the open-source nature of the project.
*   **Contextual Link:** Included the correct direct link for users back to the original repo.
*   **More Concise Explanations:** Streamlined the wording in the "How OpenEvolve Works" and "Perfect For" sections.
*   **Improved Configuration Instructions:** Reorganized the configuration and LLM setup sections.
*   **Updated the Roadmap:** Enhanced it for the purpose of a README and potential use by collaborators.
*   **Improved FAQ:** Expanded and reorganized the FAQ section to address common questions effectively.
*   **Added Bibtex:** Incorporated the code for citations for users in the research space.