# SimpleTuner: Effortless and Versatile Training for Image and Video Models

**SimpleTuner streamlines the process of fine-tuning cutting-edge image and video models, making it accessible to everyone.**

[View the original repository on GitHub](https://github.com/bghira/SimpleTuner)

SimpleTuner is designed for simplicity and ease of understanding, with a focus on providing good default settings. This project welcomes contributions from the community.

**Key Features:**

*   **Versatile Model Support:** Train a wide range of models, including Flux, Wan Video, LTX Video, PixArt Sigma, NVLabs Sana, Stable Diffusion (2.x, 3.0), Kwai Kolors, Lumina2, and Cosmos2.
*   **Hardware Optimized:** Supports training on a variety of GPUs including NVIDIA (3080 and up), AMD (7900 XTX, MI300X), and Apple (M3 Max).
*   **Memory Efficient Training:** Offers features like token-wise dropout, image/video caching, and DeepSpeed integration to reduce VRAM usage.
*   **Cutting-Edge Techniques:** Integrates advanced features like Aspect bucketing, LoRA/LyCORIS, Quantized training (NF4/INT8/FP8), EMA, Mixture of Experts, Masked Loss Training, and Prior Regularization.
*   **Flexible Data Handling:** Supports training from S3-compatible storage, integrates with the Hugging Face Hub, and includes webhook support.
*   **Quickstart Guides:** Jumpstart your training with specific guides for various models, including HiDream, Flux.1, Wan Video, LTX Video, PixArt Sigma, NVLabs Sana, Stable Diffusion 3, Kwai Kolors, Lumina2, and Cosmos2 Predict.

**Main Sections:**

*   [Design Philosophy](#design-philosophy)
*   [Tutorial](#tutorial)
*   [Features](#features)
*   [Hardware Requirements](#hardware-requirements)
*   [Toolkit](#toolkit)
*   [Setup](#setup)
*   [Troubleshooting](#troubleshooting)

**Stay Connected:**
Join our community on [Discord](https://discord.com/invite/eq3cAMZtCC) to ask questions and share your experiences.